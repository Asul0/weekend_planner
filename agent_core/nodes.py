import logging
from typing import Dict, List, Optional, Any, Tuple, Set
from datetime import datetime, date, timedelta  # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ date –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω
import asyncio  # –î–ª—è asyncio.gather –≤ –Ω–æ–≤–æ–π –ª–æ–≥–∏–∫–µ
import re

# Pydantic –∏ Langchain –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏–π –∏ —Å—Ö–µ–º
from pydantic import BaseModel, Field, ValidationError
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage
from langchain_core.tools import BaseTool

# –ù–∞—à–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –º–æ–¥—É–ª–∏
from agent_core.agent_state import AgentState, CollectedUserData
from llm_interface.gigachat_client import get_gigachat_client
from prompts.system_prompts import (
    INITIAL_INFO_EXTRACTION_PROMPT,
    GENERAL_CLARIFICATION_PROMPT_TEMPLATE,
    TIME_CLARIFICATION_PROMPT_TEMPLATE,
    PLAN_FEEDBACK_ANALYSIS_PROMPT,
    CHANGE_CONFIRMATION_PROMPT_TEMPLATE,
    EVENT_NOT_FOUND_PROMPT_TEMPLATE,
)
from schemas.data_schemas import (
    ExtractedInitialInfo,
    DateTimeParserToolArgs,
    EventSearchToolArgs,
    LocationModel,
    RouteBuilderToolArgs,
    Event,
    RouteDetails,
    ParsedDateTime,
    AnalyzedFeedback,
    RouteSegment,
)
from services.afisha_service import fetch_cities_internal  # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –µ—Å—Ç—å
from services.gis_service import get_coords_from_address, get_route
from tools.datetime_parser_tool import datetime_parser_tool
from tools.event_search_tool import event_search_tool
from tools.route_builder_tool import route_builder_tool
from services.gis_service import (
    get_geocoding_details,
    get_route,
    GeocodingResult,
)  # <--- –ò–ó–ú–ï–ù–ï–ù–û

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger(__name__)


# --- –£–∑–µ–ª 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ---
async def extract_initial_info_node(state: AgentState) -> Dict[str, Any]:
    logger.info("Node: extract_initial_info_node executing...")
    awaiting_clarification_field: Optional[str] = state.get("awaiting_clarification_for_field")
    logger.info(f"extract_initial_info_node: Received awaiting_clarification_for_field = '{awaiting_clarification_field}'")

    messages: List[BaseMessage] = state.get("messages", [])
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º dict() –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–∑–º–µ–Ω—è–µ–º–æ–π –∫–æ–ø–∏–∏, –µ—Å–ª–∏ collected_data —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –∏–Ω–∞—á–µ –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
    current_collected_data_dict: dict = dict(state.get("collected_data", {})) 

    clarification_context_for_node: Optional[str] = None
    # new_clarification_needed –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è —Å–±–æ—Ä–∞ –ø–æ–ª–µ–π, —Ç—Ä–µ–±—É—é—â–∏—Ö —É—Ç–æ—á–Ω–µ–Ω–∏—è –≤ —ç—Ç–æ–º –≤—ã–∑–æ–≤–µ —É–∑–ª–∞
    new_clarification_needed_in_this_step: List[str] = []


    if not messages or not isinstance(messages[-1], HumanMessage):
        # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –∏–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –Ω–µ –æ—Ç —á–µ–ª–æ–≤–µ–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–µ—Ä–≤—ã–π –≤—ã–∑–æ–≤ –≥—Ä–∞—Ñ–∞ –±–µ–∑ –≤–≤–æ–¥–∞)
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –Ω–æ —Å –ø—É—Å—Ç—ã–º clarification_context
        # –≠—Ç–æ –≤–∞–∂–Ω–æ, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Ü–∏–∫–ª–∏—Ç—å—Å—è, –µ—Å–ª–∏ –≥—Ä–∞—Ñ –≤—ã–∑–≤–∞–Ω –±–µ–∑ –Ω–∞—á–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        logger.warning("extract_initial_info_node: No messages or last message is not HumanMessage. Returning current state.")
        # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤—ã–π –≤—Ö–æ–¥, –∏ –º—ã –æ–∂–∏–¥–∞–µ–º, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —á—Ç–æ-—Ç–æ —Å–∫–∞–∂–µ—Ç,
        # —Ç–æ, –≤–æ–∑–º–æ–∂–Ω–æ, –≥—Ä–∞—Ñ –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã–ª —Å—é–¥–∞ –ø–æ–ø–∞–¥–∞—Ç—å –±–µ–∑ UserMessage.
        # –û–¥–Ω–∞–∫–æ, –µ—Å–ª–∏ —ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ, –Ω—É–∂–Ω–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å, —á—Ç–æ –º—ã –Ω–µ –∑–∞—Ü–∏–∫–ª–∏–º—Å—è –Ω–∞ –∑–∞–ø—Ä–æ—Å–µ —É—Ç–æ—á–Ω–µ–Ω–∏–π.
        # –ï—Å–ª–∏ clarification_needed_fields —É–∂–µ –µ—Å—Ç—å –≤ —Å—Ç–µ–π—Ç–µ, –æ–Ω–∏ –æ—Å—Ç–∞–Ω—É—Ç—Å—è.
        # –ï—Å–ª–∏ –Ω–µ—Ç, —Ç–æ –∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞—Ç—å –Ω–µ—á–µ–≥–æ.
        return {
            "collected_data": current_collected_data_dict,
            "messages": messages,
            "clarification_context": None, # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω –±—ã–ª
            "awaiting_clarification_for_field": awaiting_clarification_field # –°–æ—Ö—Ä–∞–Ω—è–µ–º, –µ—Å–ª–∏ –∂–¥–µ–º —á—Ç–æ-—Ç–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ
        }

    user_query = messages[-1].content.strip()
    user_query_lower = user_query.lower()

    reset_commands = ["–Ω–æ–≤—ã–π –ø–æ–∏—Å–∫", "–Ω–∞—á–Ω–∏ —Å–Ω–∞—á–∞–ª–∞", "–æ—Ç–º–µ–Ω–∞", "—Å–±—Ä–æ—Å", "—Å—Ç–æ–ø", "reset"]
    if any(cmd in user_query_lower for cmd in reset_commands):
        logger.info(f"User requested reset with: '{user_query}'")
        reset_message = "–•–æ—Ä–æ—à–æ, –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫! –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ, —á—Ç–æ –±—ã –≤—ã —Ö–æ—Ç–µ–ª–∏ –Ω–∞–π—Ç–∏: –≥–æ—Ä–æ–¥, –¥–∞—Ç—ã –∏ –≤–∞—à–∏ –∏–Ω—Ç–µ—Ä–µ—Å—ã. üòä"
        return {
            "collected_data": {}, # –ü–æ–ª–Ω—ã–π —Å–±—Ä–æ—Å —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            "current_events": [],
            "current_route_details": None,
            "messages": messages + [AIMessage(content=reset_message)],
            "status_message_to_user": reset_message,
            "clarification_needed_fields": [], # –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø–æ–ª–µ–π –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è
            "clarification_context": None, # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è
            "awaiting_clarification_for_field": None, # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –æ–∂–∏–¥–∞–µ–º–æ–µ –ø–æ–ª–µ
            "is_initial_plan_proposed": False,
            "is_full_plan_with_route_proposed": False,
            "awaiting_final_confirmation": False,
            "pending_plan_modification_request": None,
            "previous_confirmed_collected_data": None,
            "previous_confirmed_events": None,
        }

    # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å ---
    if awaiting_clarification_field:
        logger.info(f"Processing '{user_query}' as clarification for '{awaiting_clarification_field}'")
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π —Å–ø–∏—Å–æ–∫ –ø–æ–ª–µ–π, —Ç—Ä–µ–±—É—é—â–∏—Ö —É—Ç–æ—á–Ω–µ–Ω–∏—è, –∏–∑ collected_data
        # –≠—Ç–æ –≤–∞–∂–Ω–æ, —Ç–∞–∫ –∫–∞–∫ new_clarification_needed_in_this_step - —ç—Ç–æ –¥–ª—è –¢–ï–ö–£–©–ï–ì–û —à–∞–≥–∞.
        # –ê current_collected_data_dict["clarification_needed_fields"] - —ç—Ç–æ —Ç–æ, —á—Ç–æ –±—ã–ª–æ –î–û —ç—Ç–æ–≥–æ —à–∞–≥–∞.
        existing_clarification_fields = list(current_collected_data_dict.get("clarification_needed_fields", []))

        # –£–¥–∞–ª—è–µ–º –ø–æ–ª–µ, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –ø—Ä–∏—à–ª–æ —É—Ç–æ—á–Ω–µ–Ω–∏–µ, –∏–∑ —Å–ø–∏—Å–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —É—Ç–æ—á–Ω–µ–Ω–∏–π
        if awaiting_clarification_field in existing_clarification_fields:
            existing_clarification_fields.remove(awaiting_clarification_field)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —É—Ç–æ—á–Ω–µ–Ω–∏–µ –∫ current_collected_data_dict
        if awaiting_clarification_field == "city_name":
            current_collected_data_dict["city_name"] = user_query
            cities = await fetch_cities_internal() # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∞
            found_city = next((c for c in cities if user_query.lower() in c["name_lower"]), None)
            if found_city:
                current_collected_data_dict["city_id_afisha"] = found_city["id"]
                logger.info(f"Clarified city: '{user_query}' mapped to ID {found_city['id']}")
            else:
                current_collected_data_dict["city_id_afisha"] = None
                clarification_context_for_node = f"–ì–æ—Ä–æ–¥ '{user_query}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —É–∫–∞–∑–∞—Ç—å –¥—Ä—É–≥–æ–π –≥–æ—Ä–æ–¥."
                if "city_name" not in existing_clarification_fields: # –ï—Å–ª–∏ –µ–≥–æ —Ç–∞–º –Ω–µ –±—ã–ª–æ, –¥–æ–±–∞–≤–ª—è–µ–º —Å–Ω–æ–≤–∞
                    existing_clarification_fields.append("city_name")

        elif awaiting_clarification_field == "dates_description_original":
            current_collected_data_dict["dates_description_original"] = user_query
            current_collected_data_dict["raw_time_description_original"] = None # –°–±—Ä–∞—Å—ã–≤–∞–µ–º, –µ—Å–ª–∏ —É—Ç–æ—á–Ω—è–µ–º –≤—Å—é –¥–∞—Ç—É
            # –í—ã–∑—ã–≤–∞–µ–º datetime_parser_tool
            parsed_dt_result = await datetime_parser_tool.ainvoke({
                "natural_language_date": user_query,
                "natural_language_time_qualifier": None, # –ü—Ä–∏ —É—Ç–æ—á–Ω–µ–Ω–∏–∏ –¥–∞—Ç—ã, –≤—Ä–µ–º—è –Ω–µ –ø–µ—Ä–µ–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ
                "base_date_iso": datetime.now().isoformat()
            })
            if parsed_dt_result.get("datetime_iso"):
                current_collected_data_dict["parsed_dates_iso"] = [parsed_dt_result["datetime_iso"]]
                current_collected_data_dict["parsed_end_dates_iso"] = [parsed_dt_result["end_datetime_iso"]] if parsed_dt_result.get("end_datetime_iso") else None
                logger.info(f"Clarified dates: '{user_query}' parsed to ISO {current_collected_data_dict['parsed_dates_iso']}")
                if parsed_dt_result.get("is_ambiguous"):
                    clarification_context_for_node = parsed_dt_result.get("clarification_needed")
                    if "dates_description_original" not in existing_clarification_fields:
                         existing_clarification_fields.append("dates_description_original")
            else:
                clarification_context_for_node = parsed_dt_result.get("clarification_needed") or "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —É—Ç–æ—á–Ω–µ–Ω–Ω—É—é –¥–∞—Ç—É. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
                if "dates_description_original" not in existing_clarification_fields:
                    existing_clarification_fields.append("dates_description_original")
        
        elif awaiting_clarification_field == "interests_original":
            raw_interests_list_clarified = [i.strip() for i in user_query.split(",") if i.strip()]
            current_collected_data_dict["interests_original"] = raw_interests_list_clarified
            
            mapped_interest_keys_clarified = []
            user_requested_restaurant_explicitly_clarified = False
            for interest_str in raw_interests_list_clarified:
                s = interest_str.lower().strip()
                key = None
                # <<< –ö–û–ü–ò–†–£–ï–ú –ë–õ–û–ö –ú–ê–ü–ü–ò–ù–ì–ê –ò–ù–¢–ï–†–ï–°–û–í –û–¢–°–Æ–î–ê >>>
                if "–∫–∏–Ω–æ" == s or "—Ñ–∏–ª—å–º" == s or "—Ñ–∏–ª—å–º—ã" == s or "–∫–∏–Ω–æ—Ç–µ–∞—Ç—Ä" == s: key = "Movie"
                elif "—Ç–µ–∞—Ç—Ä" == s or "—Å–ø–µ–∫—Ç–∞–∫–ª—å" == s or "—Å–ø–µ–∫—Ç–∞–∫–ª–∏" == s or "–ø—å–µ—Å" in s: key = "Performance"
                elif "–æ–ø–µ—Ä" in s or "–±–∞–ª–µ—Ç" == s: key = "OperaBallet"
                elif "–∫–æ–Ω—Ü–µ—Ä—Ç" == s or "–∫–æ–Ω—Ü–µ—Ä—Ç—ã" == s: key = "Concert"
                elif "–≤—ã—Å—Ç–∞–≤–∫" in s or "—ç–∫—Å–ø–æ–∑–∏—Ü–∏" in s: key = "Exhibition"
                elif "—Ñ–µ—Å—Ç–∏–≤–∞–ª" in s or "—Ñ–µ—Å—Ç" == s: key = "Festival"
                elif "—Å—Ç–µ–Ω–¥–∞–ø" in s or "stand-up" in s or "stand up" in s: key = "StandUp"
                elif "—Å–ø–æ—Ä—Ç" == s or "–º–∞—Ç—á" == s or "—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏" in s: key = "SportEvent"
                elif "–≤–µ—á–µ—Ä–∏–Ω" in s or "–ø–∞—Ç–∏" == s or "party" == s or "—Ç—É—Å–æ–≤–∫" in s or "–¥–∏—Å–∫–æ—Ç–µ–∫" in s: key = "Party"
                elif "–∫–≤–∏–∑" == s or "quiz" == s or "–≤–∏–∫—Ç–æ—Ä–∏–Ω" in s : key = "Quiz"
                elif "–º–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å" in s or "–º–∞—Å—Ç–µ—Ä –∫–ª–∞—Å—Å" in s or "–≤–æ—Ä–∫—à–æ–ø" == s or "workshop" == s: key = "MasterClass"
                elif "–ª–µ–∫—Ü–∏" in s or "—Å–µ–º–∏–Ω–∞—Ä" == s or "–¥–æ–∫–ª–∞–¥" in s or ("–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏" in s and "–ø—Ä–µ—Å—Å" not in s): key = "Lecture"
                elif "—ç–∫—Å–∫—É—Ä—Å" in s: key = "Excursion"
                elif "–º—É–∑–µ–π" in s or "–º—É–∑–µ–∏" == s: key = "Museum"
                elif "—Ä–µ—Å—Ç–æ—Ä–∞–Ω" in s or "–∫–∞—Ñ–µ" == s or "–±–∞—Ä" == s or "–ø–æ–µ—Å—Ç—å" in s or "–ø–æ–∫—É—à–∞—Ç—å" in s:
                    user_requested_restaurant_explicitly_clarified = True
                
                if key: mapped_interest_keys_clarified.append(key)

            current_collected_data_dict["interests_keys_afisha"] = list(set(mapped_interest_keys_clarified)) if mapped_interest_keys_clarified else None
            logger.info(f"Clarified interests: '{user_query}' mapped to Afisha keys: {current_collected_data_dict['interests_keys_afisha']}")

            if user_requested_restaurant_explicitly_clarified and not current_collected_data_dict["interests_keys_afisha"]:
                clarification_context_for_node = "–ü–æ—Ö–æ–∂–µ, –≤—ã —Å–Ω–æ–≤–∞ —É–∫–∞–∑–∞–ª–∏ —Ç–æ–ª—å–∫–æ —Ä–µ—Å—Ç–æ—Ä–∞–Ω—ã. –Ø –Ω–µ –º–æ–≥—É –∏—Ö –∏—Å–∫–∞—Ç—å –∫–∞–∫ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞–∑–æ–≤–∏—Ç–µ –¥—Ä—É–≥–∏–µ —Ç–∏–ø—ã –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π."
                if "interests_original" not in existing_clarification_fields:
                    existing_clarification_fields.append("interests_original")
            elif not current_collected_data_dict["interests_keys_afisha"] and raw_interests_list_clarified: # –í–≤–µ–ª–∏ —á—Ç–æ-—Ç–æ, –Ω–æ –Ω–µ —Å–º–∞–ø–∏–ª–æ—Å—å
                clarification_context_for_node = "–ù–µ —Å–º–æ–≥ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≤–∞—à–∏ —É—Ç–æ—á–Ω–µ–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–∏–Ω–æ, —Ç–µ–∞—Ç—Ä)."
                if "interests_original" not in existing_clarification_fields:
                     existing_clarification_fields.append("interests_original")

        elif awaiting_clarification_field == "budget_original":
            try:
                budget_val_match = re.search(r"\d+", user_query)
                if budget_val_match:
                    budget_val = int(budget_val_match.group(0))
                    current_collected_data_dict["budget_original"] = budget_val
                    current_collected_data_dict["budget_current_search"] = budget_val
                    logger.info(f"Clarified budget: {budget_val}")
                else:
                    raise ValueError("No digits in budget input")
            except ValueError:
                clarification_context_for_node = "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –±—é–¥–∂–µ—Ç —á–∏—Å–ª–æ–º."
                if "budget_original" not in existing_clarification_fields:
                     existing_clarification_fields.append("budget_original")
        
        elif awaiting_clarification_field == "user_start_address_original":
            logger.info(f"Processing address clarification: '{user_query}'")
            city_for_geocoding = current_collected_data_dict.get("city_name")
            previously_found_street = current_collected_data_dict.get("partial_address_street")
            address_to_geocode = user_query
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –æ–∂–∏–¥–∞–Ω–∏—è –≤–≤–æ–¥–∞ –∞–¥—Ä–µ—Å–∞ (awaiting_address_input –±—ã–ª –≤ —Å—Ç–∞—Ä–æ–π —Å—Ö–µ–º–µ, —Å–µ–π—á–∞—Å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —è–≤–Ω–æ –≤ AgentState)
            # –ù–æ –µ—Å–ª–∏ –æ–Ω –±—ã–ª –≤ current_collected_data_dict, –µ–≥–æ –Ω—É–∂–Ω–æ —É–±—Ä–∞—Ç—å –∏–ª–∏ –ø–æ—Å—Ç–∞–≤–∏—Ç—å False
            current_collected_data_dict.pop("awaiting_address_input", None) 

            if previously_found_street and not any(c.isalpha() for c in user_query if c.isalpha() and c.lower() not in "–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è"):
                address_to_geocode = f"{previously_found_street}, {user_query}"

            if not city_for_geocoding:
                clarification_context_for_node = "–î–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –∞–¥—Ä–µ—Å–∞ –º–Ω–µ —Å–Ω–∞—á–∞–ª–∞ –Ω—É–∂–Ω–æ –∑–Ω–∞—Ç—å –≥–æ—Ä–æ–¥. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –≥–æ—Ä–æ–¥."
                if "city_name" not in existing_clarification_fields: existing_clarification_fields.append("city_name")
                current_collected_data_dict.pop("partial_address_street", None) # –°–±—Ä–æ—Å —á–∞—Å—Ç–∏—á–Ω–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–π —É–ª–∏—Ü—ã
            else:
                geocoding_result: GeocodingResult = await get_geocoding_details(address=address_to_geocode, city=city_for_geocoding)
                if geocoding_result.is_precise_enough and geocoding_result.coords:
                    current_collected_data_dict["user_start_address_original"] = geocoding_result.full_address_name_gis
                    current_collected_data_dict["user_start_address_validated_coords"] = {"lon": geocoding_result.coords[0], "lat": geocoding_result.coords[1]}
                    current_collected_data_dict.pop("partial_address_street", None)
                    logger.info(f"Address '{address_to_geocode}' geocoded successfully to {geocoding_result.full_address_name_gis}")
                elif geocoding_result.match_level == "street" and not previously_found_street : # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤—ã–π —Ä–∞–∑ —É–ª–∏—Ü–∞ –Ω–∞–π–¥–µ–Ω–∞
                    clarification_context_for_node = f"–ù–∞—à–µ–ª —É–ª–∏—Ü—É '{geocoding_result.full_address_name_gis}'. –£—Ç–æ—á–Ω–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–æ–º–µ—Ä –¥–æ–º–∞."
                    current_collected_data_dict["partial_address_street"] = geocoding_result.full_address_name_gis
                    if "user_start_address_original" not in existing_clarification_fields:
                         existing_clarification_fields.append("user_start_address_original")
                else: # –ù–µ—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–ª–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ —É–ª–∏—Ü—ã
                    clarification_context_for_node = f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ç–æ—á–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∞–¥—Ä–µ—Å '{address_to_geocode}'. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–∫–∞–∑–∞—Ç—å –µ–≥–æ –µ—â–µ —Ä–∞–∑, –Ω–∞–ø—Ä–∏–º–µ—Ä: '—É–ª–∏—Ü–∞ –õ–µ–Ω–∏–Ω–∞, 10'."
                    current_collected_data_dict.pop("partial_address_street", None) # –°–±—Ä–∞—Å—ã–≤–∞–µ–º, –µ—Å–ª–∏ –Ω–µ –ø–æ–º–æ–≥–ª–æ
                    if "user_start_address_original" not in existing_clarification_fields:
                         existing_clarification_fields.append("user_start_address_original")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –ø–æ–ª–µ–π –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –≤ —Å—Ç–µ–π—Ç–µ
        current_collected_data_dict["clarification_needed_fields"] = [f for f in existing_clarification_fields if f] # –£–¥–∞–ª—è–µ–º None/–ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        current_collected_data_dict["awaiting_clarification_for_field"] = None # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–æ–ª–µ, –∫–æ—Ç–æ—Ä–æ–µ —Ç–æ–ª—å–∫–æ —á—Ç–æ —É—Ç–æ—á–Ω–∏–ª–∏

        logger.debug(f"After clarification. New collected_data: {str(current_collected_data_dict)[:300]}. Clarification context for next node: {clarification_context_for_node}")
        return {
            "collected_data": current_collected_data_dict,
            "messages": messages, # –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è —ç—Ç–∏–º —É–∑–ª–æ–º, —Ç–æ–ª—å–∫–æ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è AIMessage —Å–ª–µ–¥—É—é—â–∏–º —É–∑–ª–æ–º
            "clarification_context": clarification_context_for_node, # –ü–µ—Ä–µ–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ—à–∏–±–∫—É) –¥–∞–ª—å—à–µ
            "awaiting_clarification_for_field": None, # –ú—ã –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏ –æ–∂–∏–¥–∞–µ–º–æ–µ –ø–æ–ª–µ
        }

    # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –ù–û–í–û–ì–û (–Ω–µ —É—Ç–æ—á–Ω—è—é—â–µ–≥–æ) –∑–∞–ø—Ä–æ—Å–∞ ---
    logger.debug("extract_initial_info_node: Processing as a new/general query (awaiting_clarification_field is None).")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–¥—Ä–µ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –º–µ–∂–¥—É –Ω–æ–≤—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏ (–µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å)
    # –ì–æ—Ä–æ–¥, –¥–∞—Ç—ã, –∏–Ω—Ç–µ—Ä–µ—Å—ã, –±—é–¥–∂–µ—Ç - –¥–æ–ª–∂–Ω—ã –∏–∑–≤–ª–µ–∫–∞—Ç—å—Å—è –∏–∑ –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∏–ª–∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞—Ç—å—Å—è –∑–∞–Ω–æ–≤–æ.
    preserved_user_address_original = current_collected_data_dict.get("user_start_address_original")
    preserved_user_coords = current_collected_data_dict.get("user_start_address_validated_coords")
    
    current_collected_data_dict_for_new_query = {} # –ù–∞—á–∏–Ω–∞–µ–º —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    if preserved_user_address_original and preserved_user_coords: # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∞–¥—Ä–µ—Å –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤–∞–ª–∏–¥–µ–Ω
        current_collected_data_dict_for_new_query["user_start_address_original"] = preserved_user_address_original
        current_collected_data_dict_for_new_query["user_start_address_validated_coords"] = preserved_user_coords
        logger.debug(f"Preserving user address: {preserved_user_address_original}")

    llm = get_gigachat_client()
    structured_llm = llm.with_structured_output(ExtractedInitialInfo) # ExtractedInitialInfo - Pydantic –º–æ–¥–µ–ª—å

    try:
        extraction_prompt_with_query = f'{INITIAL_INFO_EXTRACTION_PROMPT}\n\n–ò–∑–≤–ª–µ–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n"{user_query}"'
        logger.debug(f"Sending to LLM for extraction: {user_query}")
        extracted_info: ExtractedInitialInfo = await structured_llm.ainvoke(extraction_prompt_with_query)
        logger.info(f"extract_initial_info_node: LLM Extracted Info (Pydantic): {extracted_info.model_dump_json(indent=2)}")

        # new_clarification_needed_in_this_step —É–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∫–∞–∫ []
        
        # 1. –ì–æ—Ä–æ–¥
        if extracted_info.city:
            current_collected_data_dict_for_new_query["city_name"] = extracted_info.city
            cities = await fetch_cities_internal()
            found_city = next((c for c in cities if extracted_info.city.lower() in c["name_lower"]), None)
            if found_city:
                current_collected_data_dict_for_new_query["city_id_afisha"] = found_city["id"]
            else:
                new_clarification_needed_in_this_step.append("city_name")
                clarification_context_for_node = (clarification_context_for_node or "") + f" –ì–æ—Ä–æ–¥ '{extracted_info.city}' –Ω–µ –Ω–∞–π–¥–µ–Ω. "
        else:
            new_clarification_needed_in_this_step.append("city_name")

        # 2. –ò–Ω—Ç–µ—Ä–µ—Å—ã
        user_requested_restaurant_explicitly_new = False
        if extracted_info.interests:
            current_collected_data_dict_for_new_query["interests_original"] = extracted_info.interests
            mapped_interest_keys_new = []
            for interest_str in extracted_info.interests:
                s = interest_str.lower().strip()
                key = None
                # <<< –ö–û–ü–ò–†–£–ï–ú –ë–õ–û–ö –ú–ê–ü–ü–ò–ù–ì–ê –ò–ù–¢–ï–†–ï–°–û–í –û–¢–°–Æ–î–ê (—Ç–∞–∫–æ–π –∂–µ, –∫–∞–∫ –≤ –±–ª–æ–∫–µ Clarification) >>>
                if "–∫–∏–Ω–æ" == s or "—Ñ–∏–ª—å–º" == s or "—Ñ–∏–ª—å–º—ã" == s or "–∫–∏–Ω–æ—Ç–µ–∞—Ç—Ä" == s: key = "Movie"
                elif "—Ç–µ–∞—Ç—Ä" == s or "—Å–ø–µ–∫—Ç–∞–∫–ª—å" == s or "—Å–ø–µ–∫—Ç–∞–∫–ª–∏" == s or "–ø—å–µ—Å" in s: key = "Performance"
                elif "–æ–ø–µ—Ä" in s or "–±–∞–ª–µ—Ç" == s: key = "OperaBallet"
                elif "–∫–æ–Ω—Ü–µ—Ä—Ç" == s or "–∫–æ–Ω—Ü–µ—Ä—Ç—ã" == s: key = "Concert"
                elif "–≤—ã—Å—Ç–∞–≤–∫" in s or "—ç–∫—Å–ø–æ–∑–∏—Ü–∏" in s: key = "Exhibition"
                elif "—Ñ–µ—Å—Ç–∏–≤–∞–ª" in s or "—Ñ–µ—Å—Ç" == s: key = "Festival"
                elif "—Å—Ç–µ–Ω–¥–∞–ø" in s or "stand-up" in s or "stand up" in s: key = "StandUp"
                elif "—Å–ø–æ—Ä—Ç" == s or "–º–∞—Ç—á" == s or "—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏" in s: key = "SportEvent"
                elif "–≤–µ—á–µ—Ä–∏–Ω" in s or "–ø–∞—Ç–∏" == s or "party" == s or "—Ç—É—Å–æ–≤–∫" in s or "–¥–∏—Å–∫–æ—Ç–µ–∫" in s: key = "Party"
                elif "–∫–≤–∏–∑" == s or "quiz" == s or "–≤–∏–∫—Ç–æ—Ä–∏–Ω" in s : key = "Quiz"
                elif "–º–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å" in s or "–º–∞—Å—Ç–µ—Ä –∫–ª–∞—Å—Å" in s or "–≤–æ—Ä–∫—à–æ–ø" == s or "workshop" == s: key = "MasterClass"
                elif "–ª–µ–∫—Ü–∏" in s or "—Å–µ–º–∏–Ω–∞—Ä" == s or "–¥–æ–∫–ª–∞–¥" in s or ("–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏" in s and "–ø—Ä–µ—Å—Å" not in s): key = "Lecture"
                elif "—ç–∫—Å–∫—É—Ä—Å" in s: key = "Excursion"
                elif "–º—É–∑–µ–π" in s or "–º—É–∑–µ–∏" == s: key = "Museum"
                elif "—Ä–µ—Å—Ç–æ—Ä–∞–Ω" in s or "–∫–∞—Ñ–µ" == s or "–±–∞—Ä" == s or "–ø–æ–µ—Å—Ç—å" in s or "–ø–æ–∫—É—à–∞—Ç—å" in s:
                    user_requested_restaurant_explicitly_new = True
                # <<< –î–û–°–Æ–î–ê >>>
                if key: mapped_interest_keys_new.append(key)
            
            current_collected_data_dict_for_new_query["interests_keys_afisha"] = list(set(mapped_interest_keys_new)) if mapped_interest_keys_new else None
            
            if user_requested_restaurant_explicitly_new and not current_collected_data_dict_for_new_query["interests_keys_afisha"]:
                clarification_context_for_node = (clarification_context_for_node or "") + " –Ø –Ω–µ –∏—â—É —Ä–µ—Å—Ç–æ—Ä–∞–Ω—ã –∫–∞–∫ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è. –ú–æ–≥—É –ø–æ–∏—Å–∫–∞—Ç—å –¥—Ä—É–≥–∏–µ —Ç–∏–ø—ã –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π. "
                new_clarification_needed_in_this_step.append("interests_original")
                # –û—á–∏—Å—Ç–∏–º –∏—Å—Ö–æ–¥–Ω—ã–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã, –µ—Å–ª–∏ —Ç–∞–º –±—ã–ª–∏ —Ç–æ–ª—å–∫–æ —Ä–µ—Å—Ç–æ—Ä–∞–Ω—ã
                if current_collected_data_dict_for_new_query.get("interests_original"):
                    current_collected_data_dict_for_new_query["interests_original"] = [
                        i for i in current_collected_data_dict_for_new_query["interests_original"] 
                        if not any(restr_kw in i.lower() for restr_kw in ["—Ä–µ—Å—Ç–æ—Ä–∞–Ω", "–∫–∞—Ñ–µ", "–±–∞—Ä", "–ø–æ–µ—Å—Ç—å", "–ø–æ–∫—É—à–∞—Ç—å"])
                    ]
                    if not current_collected_data_dict_for_new_query["interests_original"]:
                        current_collected_data_dict_for_new_query["interests_original"] = None
            elif not current_collected_data_dict_for_new_query["interests_keys_afisha"] and extracted_info.interests: # –ò–∑–≤–ª–µ–∫–ª–∏, –Ω–æ –Ω–µ —Å–º–∞–ø–∏–ª–∏
                new_clarification_needed_in_this_step.append("interests_original")
                clarification_context_for_node = (clarification_context_for_node or "") + " –ù–µ —É–¥–∞–ª–æ—Å—å —Ç–æ—á–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤–∞—à–∏ –∏–Ω—Ç–µ—Ä–µ—Å—ã. "
        else: # LLM –Ω–µ –∏–∑–≤–ª–µ–∫ –∏–Ω—Ç–µ—Ä–µ—Å—ã
            if not user_requested_restaurant_explicitly_new: # –ò —ç—Ç–æ –Ω–µ –±—ã–ª –Ω–µ—è–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞, –∫–æ—Ç–æ—Ä—ã–π –º—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–ª–∏
                new_clarification_needed_in_this_step.append("interests_original")

        # 3. –ë—é–¥–∂–µ—Ç
        if extracted_info.budget is not None:
            current_collected_data_dict_for_new_query["budget_original"] = extracted_info.budget
            current_collected_data_dict_for_new_query["budget_current_search"] = extracted_info.budget
        # –ó–∞–ø—Ä–æ—Å –±—é–¥–∂–µ—Ç–∞ –æ–ø—Ü–∏–æ–Ω–∞–ª–µ–Ω, –ø–æ—ç—Ç–æ–º—É –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ new_clarification_needed, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω.
        # present_initial_plan_node –º–æ–∂–µ—Ç –∑–∞–ø—Ä–æ—Å–∏—Ç—å –µ–≥–æ –ø–æ–∑–∂–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ.

        # 4. –î–∞—Ç—ã –∏ –í—Ä–µ–º—è
        date_desc_llm = extracted_info.dates_description
        time_desc_llm = extracted_info.raw_time_description
        current_collected_data_dict_for_new_query["dates_description_original"] = date_desc_llm
        current_collected_data_dict_for_new_query["raw_time_description_original"] = time_desc_llm

        if date_desc_llm or time_desc_llm: # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–ø–∏—Å–∞–Ω–∏–µ –¥–∞—Ç—ã –∏–ª–∏ –≤—Ä–µ–º–µ–Ω–∏
            # –í—ã–∑—ã–≤–∞–µ–º datetime_parser_tool
            parsed_dt_res = await datetime_parser_tool.ainvoke({
                "natural_language_date": date_desc_llm or "", # –ü–µ—Ä–µ–¥–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º—è
                "natural_language_time_qualifier": time_desc_llm,
                "base_date_iso": datetime.now().isoformat()
            })
            if parsed_dt_res.get("datetime_iso"):
                current_collected_data_dict_for_new_query["parsed_dates_iso"] = [parsed_dt_res["datetime_iso"]]
                current_collected_data_dict_for_new_query["parsed_end_dates_iso"] = [parsed_dt_res["end_datetime_iso"]] if parsed_dt_res.get("end_datetime_iso") else None
                if parsed_dt_res.get("is_ambiguous"):
                    new_clarification_needed_in_this_step.append("dates_description_original")
                    clarification_context_for_node = (clarification_context_for_node or "") + (parsed_dt_res.get("clarification_needed") or "") + " "
            else: # –ï—Å–ª–∏ –ø–∞—Ä—Å–µ—Ä –Ω–µ –≤–µ—Ä–Ω—É–ª datetime_iso
                new_clarification_needed_in_this_step.append("dates_description_original")
                clarification_context_for_node = (clarification_context_for_node or "") + (parsed_dt_res.get("clarification_needed") or "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –¥–∞—Ç—É/–≤—Ä–µ–º—è. ") + " "
        else: # –ï—Å–ª–∏ LLM –Ω–µ –∏–∑–≤–ª–µ–∫ –Ω–∏ –¥–∞—Ç—É, –Ω–∏ –≤—Ä–µ–º—è
            new_clarification_needed_in_this_step.append("dates_description_original")
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø–æ–ª–µ–π –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –∏ –æ–±—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        current_collected_data_dict_for_new_query["clarification_needed_fields"] = list(set(new_clarification_needed_in_this_step))
        
        # –ó–∞–º–µ–Ω—è–µ–º —Ç–µ–∫—É—â–∏–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –¥–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        current_collected_data_dict = current_collected_data_dict_for_new_query 

    except ValidationError as ve_llm: # –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ LLM –ø–æ Pydantic —Å—Ö–µ–º–µ
        logger.error(f"extract_initial_info_node: LLM Pydantic validation error: {ve_llm}", exc_info=True)
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –≤—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è, —Ç–∞–∫ –∫–∞–∫ –Ω–µ —Å–º–æ–≥–ª–∏ –∏–∑–≤–ª–µ—á—å
        current_collected_data_dict["clarification_needed_fields"] = list(set(["city_name", "dates_description_original", "interests_original"]))
        clarification_context_for_node = "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –î–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º —Å–æ–±—Ä–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —á–∞—Å—Ç—è–º."
    except Exception as e_llm: # –õ—é–±–∞—è –¥—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ LLM
        logger.error(f"extract_initial_info_node: LLM extraction error: {e_llm}", exc_info=True)
        current_collected_data_dict.setdefault("clarification_needed_fields", []) # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ —Å–ø–∏—Å–æ–∫ –µ—Å—Ç—å
        for f_key in ["city_name", "dates_description_original", "interests_original"]:
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–µ –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–æ –µ—â–µ –Ω–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –∏ –Ω–µ –≤ —Å–ø–∏—Å–∫–µ
            if not current_collected_data_dict.get(f_key) and f_key not in current_collected_data_dict["clarification_needed_fields"]:
                current_collected_data_dict["clarification_needed_fields"].append(f_key)
        current_collected_data_dict["clarification_needed_fields"] = list(set(current_collected_data_dict["clarification_needed_fields"]))
        clarification_context_for_node = "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ."

    logger.info(f"extract_initial_info_node: Final collected_data for this step: {str(current_collected_data_dict)[:500]}. Clarification context: {clarification_context_for_node}")
    
    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ clarification_context_for_node –Ω–µ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞, –∞ None –µ—Å–ª–∏ –Ω–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    if clarification_context_for_node is not None and not clarification_context_for_node.strip():
        clarification_context_for_node = None

    return {
        "collected_data": current_collected_data_dict,
        "messages": messages,
        "clarification_context": clarification_context_for_node,
        "awaiting_clarification_for_field": None, # –î–ª—è –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –º—ã –Ω–µ –∂–¥–µ–º —É—Ç–æ—á–Ω–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—è
    }


# --- –£–∑–µ–ª 2: –£—Ç–æ—á–Ω–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö ---
async def clarify_missing_data_node(state: AgentState) -> Dict[str, Any]:
    logger.info("Node: clarify_missing_data_node executing...")
    collected_data_dict: dict = dict(state.get("collected_data", {}))
    clarification_fields: List[str] = collected_data_dict.get(
        "clarification_needed_fields", []
    )
    status_message_to_user: Optional[str] = None
    field_being_clarified: Optional[str] = None

    if not clarification_fields:
        logger.info("clarify_missing_data_node: No fields need explicit clarification.")
        return {
            "status_message_to_user": None,
            "awaiting_clarification_for_field": None,
            "clarification_context": None,
            "collected_data": collected_data_dict,
        }

    field_to_clarify_now = clarification_fields[0]
    field_being_clarified = field_to_clarify_now

    missing_critical_fields_map = {
        "city_name": "–≥–æ—Ä–æ–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞",
        "dates_description_original": "–¥–∞—Ç—ã –∏–ª–∏ –ø–µ—Ä–∏–æ–¥ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π",
        "interests_original": "–≤–∞—à–∏ –∏–Ω—Ç–µ—Ä–µ—Å—ã –∏–ª–∏ —Ç–∏–ø –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π",
        "budget_original": "–≤–∞—à –ø—Ä–∏–º–µ—Ä–Ω—ã–π –±—é–¥–∂–µ—Ç",
        "user_start_address_original": "–≤–∞—à –∞–¥—Ä–µ—Å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è (—É–ª–∏—Ü–∞ –∏ –¥–æ–º)",
    }

    clarification_context_from_state = state.get("clarification_context")
    if (
        isinstance(clarification_context_from_state, str)
        and clarification_context_from_state
    ):
        status_message_to_user = clarification_context_from_state
        logger.info(
            f"clarify_missing_data_node: Using pre-defined clarification context: {status_message_to_user}"
        )
    else:
        field_description_for_prompt = missing_critical_fields_map.get(
            field_to_clarify_now, f"–ø–æ–ª–µ '{field_to_clarify_now}'"
        )

        raw_time_desc = collected_data_dict.get("raw_time_description_original")
        prompt_for_llm: str
        if field_to_clarify_now == "dates_description_original" and raw_time_desc:
            prompt_for_llm = TIME_CLARIFICATION_PROMPT_TEMPLATE.format(
                raw_time_description=raw_time_desc,
                current_date_info=date.today().strftime("%d %B %Y –≥–æ–¥–∞ (%A)"),
            )
        else:
            last_user_message_content = "–í–∞—à –∑–∞–ø—Ä–æ—Å"
            current_messages = state.get("messages", [])
            if current_messages and isinstance(current_messages[-1], HumanMessage):
                last_user_message_content = current_messages[-1].content

            # –§–æ—Ä–º–∏—Ä—É–µ–º summary –±–µ–∑ –ø–æ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏–ª–∏ –∫–æ—Ç–æ—Ä—ã–µ —Å–ª—É–∂–µ–±–Ω—ã–µ
            excluded_keys_for_summary = [
                "clarification_needed_fields",
                "awaiting_clarification_for_field",
                "awaiting_address_input",
                "partial_address_street",
                "awaiting_fallback_confirmation",
                "pending_fallback_event",
                "fallback_accepted_and_plan_updated",
                "previous_confirmed_collected_data",
                "previous_confirmed_events",
                "user_time_desc_for_fallback",
                "not_found_interest_keys",
                "fallback_candidates",
            ]
            current_data_summary_parts = []
            for k, v in collected_data_dict.items():
                if v and k not in excluded_keys_for_summary:
                    # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª–µ–µ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –∫–ª—é—á–µ–π
                    if k == "city_name":
                        current_data_summary_parts.append(f"–ì–æ—Ä–æ–¥: {v}")
                    elif k == "dates_description_original":
                        current_data_summary_parts.append(f"–ö–æ–≥–¥–∞: {v}")
                    elif k == "interests_original":
                        current_data_summary_parts.append(
                            f"–ò–Ω—Ç–µ—Ä–µ—Å—ã: {', '.join(v) if isinstance(v, list) else v}"
                        )
                    elif k == "budget_original":
                        current_data_summary_parts.append(f"–ë—é–¥–∂–µ—Ç: –¥–æ {v} —Ä—É–±.")
                    # –î–æ–±–∞–≤—å –¥—Ä—É–≥–∏–µ –ø–æ–ª—è –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

            current_data_summary_str = (
                "; ".join(current_data_summary_parts)
                if current_data_summary_parts
                else "–ø–æ–∫–∞ –Ω–∏—á–µ–≥–æ –Ω–µ —É—Ç–æ—á–Ω–µ–Ω–æ"
            )

            prompt_for_llm = GENERAL_CLARIFICATION_PROMPT_TEMPLATE.format(
                user_query=last_user_message_content,
                current_collected_data_summary=current_data_summary_str,
                missing_fields_description=field_description_for_prompt,
            )

        logger.debug(
            f"clarify_missing_data_node: Using LLM prompt for '{field_description_for_prompt}'"
        )
        llm = get_gigachat_client()
        try:
            ai_response = await llm.ainvoke(prompt_for_llm)
            status_message_to_user = ai_response.content
            logger.info(
                f"clarify_missing_data_node: LLM generated clarification question: {status_message_to_user}"
            )
        except Exception as e_clarify:
            logger.error(
                f"clarify_missing_data_node: Error during LLM call: {e_clarify}",
                exc_info=True,
            )
            status_message_to_user = f"–ú–Ω–µ –Ω—É–∂–Ω–æ —É—Ç–æ—á–Ω–µ–Ω–∏–µ –ø–æ –ø–æ–ª—é: {field_description_for_prompt}. –ù–µ –º–æ–≥–ª–∏ –±—ã –≤—ã –ø–æ–º–æ—á—å?"

    final_message_to_user = (
        status_message_to_user
        or f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ {field_description_for_prompt}."
    )
    new_messages_history = state.get("messages", []) + [
        AIMessage(content=final_message_to_user)
    ]

    # –û–±–Ω–æ–≤–ª—è–µ–º clarification_needed_fields –≤ collected_data, —á—Ç–æ–±—ã –≤ —Å–ª–µ–¥—É—é—â–µ–º —à–∞–≥–µ (–≤ —Ä–µ–±—Ä–µ)
    # –Ω–µ –±—ã–ª–æ —ç—Ç–æ–≥–æ –ø–æ–ª—è, –µ—Å–ª–∏ –º—ã –ø–æ –Ω–µ–º—É —É–∂–µ —Å–ø—Ä–æ—Å–∏–ª–∏.
    # –ù–æ —ç—Ç–æ –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ, –≤–æ–∑–º–æ–∂–Ω–æ, –ª—É—á—à–µ —ç—Ç–æ –¥–µ–ª–∞—Ç—å –≤ extract_initial_info –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.
    # –ü–æ–∫–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å, —á—Ç–æ–±—ã awaiting_clarification_for_field –±—ã–ª –≥–ª–∞–≤–Ω—ã–º.

    return {
        "messages": new_messages_history,
        "status_message_to_user": final_message_to_user,
        "awaiting_clarification_for_field": field_being_clarified,
        "clarification_context": None,
        "collected_data": collected_data_dict,  # –ü–µ—Ä–µ–¥–∞–µ–º collected_data –¥–∞–ª—å—à–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —ç—Ç–æ–º —É–∑–ª–µ
    }



# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø SEARCH_EVENTS_NODE ---

async def _fetch_events_via_tool_for_interest(
    internal_key: str,
    city_id: int,
    api_date_from_dt: datetime, 
    api_date_to_dt: datetime,   
    min_start_event_time_filter: Optional[datetime], 
    max_start_event_time_filter: Optional[datetime], 
    budget: Optional[int],
    user_max_overall_end_dt_naive_plan: Optional[datetime] 
) -> List[Event]:
    logger.debug(
        f"_fetch_events_via_tool: key='{internal_key}', city={city_id}, "
        f"API_dates=[{api_date_from_dt.date()} to {api_date_to_dt.date()-timedelta(days=1)}], "
        f"min_event_start={min_start_event_time_filter}, max_event_start={max_start_event_time_filter}, "
        f"user_max_plan_end={user_max_overall_end_dt_naive_plan}"
    )
    try:
        event_dicts_from_tool: List[Dict] = await event_search_tool.ainvoke({
            "city_id": city_id,
            "date_from": api_date_from_dt, # –≠—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –æ–∂–∏–¥–∞–µ—Ç event_search_tool
            "date_to": api_date_to_dt,     # –≠—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –æ–∂–∏–¥–∞–µ—Ç event_search_tool
            "interests_keys": [internal_key], 
            "min_start_time_naive": min_start_event_time_filter,
            "max_start_time_naive": max_start_event_time_filter,
            "max_budget_per_person": budget,
            "exclude_session_ids": None,
        })
        
        valid_events: List[Event] = []
        if not isinstance(event_dicts_from_tool, list):
            logger.error(f"event_search_tool for key '{internal_key}' returned non-list: {type(event_dicts_from_tool)}")
            return []

        for evt_dict in event_dicts_from_tool:
            if not isinstance(evt_dict, dict):
                logger.warning(f"Skipping non-dict item from event_search_tool for key '{internal_key}': {type(evt_dict)}")
                continue
            try:
                event_obj = Event(**evt_dict) 
                
                if user_max_overall_end_dt_naive_plan:
                    # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è —Å–æ–±—ã—Ç–∏—è
                    event_duration_minutes = event_obj.duration_minutes or 120 # –î–µ—Ñ–æ–ª—Ç–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –µ—Å–ª–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞
                    event_end_time_approx = event_obj.start_time_naive_event_tz + timedelta(minutes=event_duration_minutes)
                    if event_end_time_approx > user_max_overall_end_dt_naive_plan:
                        logger.debug(f"Filtering out event '{event_obj.name}' (key: {internal_key}) as it ends ({event_end_time_approx}) after user_max_overall_plan_end_time ({user_max_overall_end_dt_naive_plan})")
                        continue
                
                valid_events.append(event_obj)
            except ValidationError as ve:
                logger.warning(f"Validation error for event data from tool for key '{internal_key}': {str(evt_dict)[:300]}. Error: {ve}")
        
        valid_events.sort(key=lambda e: e.start_time_naive_event_tz) # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å—Ä–∞–∑—É
        logger.info(f"Fetched and validated {len(valid_events)} events for internal_key='{internal_key}'")
        return valid_events
    except Exception as e_tool_invoke:
        logger.error(f"Error invoking event_search_tool for internal_key='{internal_key}': {e_tool_invoke}", exc_info=True)
        return []

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–æ–±—ã—Ç–∏–π ---

def _is_event_standup(event: Event) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–±—ã—Ç–∏–µ —Å—Ç–µ–Ω–¥–∞–ø–æ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –µ–≥–æ –¥–∞–Ω–Ω—ã—Ö."""
    if not event:
        return False

    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ API, —Å –∫–æ—Ç–æ—Ä—ã–º –º—ã –µ–≥–æ –∏—Å–∫–∞–ª–∏ (–æ–∂–∏–¥–∞–µ–º Concert)
    # actual_api_type –±–µ—Ä–µ—Ç—Å—è –∏–∑ –ø–æ–ª—è 'Type' —Å–∞–º–æ–≥–æ Creation –∏–∑ API
    if event.actual_api_type != "Concert":
        logger.debug(f"Event '{event.name}' (actual_api_type: {event.actual_api_type}) is not 'Concert', skipping StandUp check.")
        return False

    name_lower = event.name.lower()
    description_lower = ((event.description or "") + " " + (event.short_description or "")).lower()
    genres_lower = [g.lower() for g in (event.genres or [])]

    standup_keywords_name = ["—Å—Ç–µ–Ω–¥–∞–ø", "stand-up", "stand up", "–æ—Ç–∫—Ä—ã—Ç—ã–π –º–∏–∫—Ä–æ—Ñ–æ–Ω", "–ø—Ä–æ–≤–µ—Ä–∫–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞", "–∫–æ–º–∏–∫", "—Å–æ–ª—å–Ω—ã–π –∫–æ–Ω—Ü–µ—Ä—Ç"] # –î–æ–±–∞–≤–∏–ª "—Å–æ–ª—å–Ω—ã–π –∫–æ–Ω—Ü–µ—Ä—Ç"
    standup_keywords_description = ["—Å—Ç–µ–Ω–¥–∞–ø", "stand-up", "–∫–æ–º–∏–∫", "—é–º–æ—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —à–æ—É", "–≤–µ—á–µ—Ä –∫–æ–º–µ–¥–∏–∏", "—à—É—Ç–∫–∏", "–º–æ–Ω–æ–ª–æ–≥–∏"]
    standup_genre_keywords = ["humor", "—é–º–æ—Ä"] # "comedy" –º–æ–∂–µ—Ç –±—ã—Ç—å —É –∫–æ–º–µ–¥–∏–π–Ω—ã—Ö —Å–ø–µ–∫—Ç–∞–∫–ª–µ–π

    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, —É–∫–∞–∑—ã–≤–∞—é—â–∏–µ, —á—Ç–æ —ç—Ç–æ –ù–ï —Å—Ç–µ–Ω–¥–∞–ø (–¥–∞–∂–µ –µ—Å–ª–∏ —Ç–∏–ø "Concert")
    negative_keywords = [
        "–ø–æ—ç–∑–∏–∏", "–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã–π", "–º–∞—è–∫–æ–≤—Å–∫–∏–π", "–µ—Å–µ–Ω–∏–Ω", "—Å—Ç–∏—Ö–∏", "–º—É–∑—ã–∫–∞–ª—å–Ω—ã–π",
        "–≥—Ä—É–ø–ø—ã", "–ø–µ—Å–Ω–∏", "—Å–ø–µ–∫—Ç–∞–∫–ª—å", "–ø—å–µ—Å–∞", "—Ç–µ–∞—Ç—Ä", "–¥—Ä–∞–º–∞", "–æ–ø–µ—Ä–∞", "–±–∞–ª–µ—Ç"
    ]

    if any(neg_kw in name_lower or neg_kw in description_lower for neg_kw in negative_keywords):
        logger.debug(f"Event '{event.name}' filtered out as non-standup (negative keywords).")
        return False

    name_match = any(kw in name_lower for kw in standup_keywords_name)
    desc_match = any(kw in description_lower for kw in standup_keywords_description)
    genre_match = any(gkw in genres_lower for gkw in standup_genre_keywords)
    
    place_name_match = False
    if event.place_name and ("—Å—Ç–µ–Ω–¥–∞–ø-–∫–ª—É–±" in event.place_name.lower() or "comedy club" in event.place_name.lower()):
        place_name_match = True

    # –°—á–∏—Ç–∞–µ–º —Å—Ç–µ–Ω–¥–∞–ø–æ–º, –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä—è–º–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏,
    # –∏–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ/–∂–∞–Ω—Ä/–º–µ—Å—Ç–æ –∏ –Ω–µ—Ç —è–≤–Ω—ã—Ö –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    if name_match: # –ï—Å–ª–∏ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –µ—Å—Ç—å "—Å—Ç–µ–Ω–¥–∞–ø" –∏ —Ç.–ø. - —ç—Ç–æ —Å–∞–º—ã–π —Å–∏–ª—å–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫
        return True
    if place_name_match and (desc_match or genre_match): # –ï—Å–ª–∏ –≤ —Å—Ç–µ–Ω–¥–∞–ø-–∫–ª—É–±–µ –∏ –µ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ —é–º–æ—Ä–∞/–∫–æ–º–µ–¥–∏–∏
        return True
    if genre_match and desc_match: # –ï—Å–ª–∏ –∂–∞–Ω—Ä —é–º–æ—Ä –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ–¥—Ö–æ–¥—è—â–µ–µ
        return True
    
    # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–ª–∏ —Ç–æ–ª—å–∫–æ –∂–∞–Ω—Ä (–±–µ–∑ —è–≤–Ω–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è –∏–ª–∏ –º–µ—Å—Ç–∞) - –º–æ–∂–µ–º –±—ã—Ç—å –±–æ–ª–µ–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã
    # –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –ø—Ä–æ—Å—Ç–æ genre_match, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∫–æ–º–µ–¥–∏–π–Ω—ã–π –∫–æ–Ω—Ü–µ—Ä—Ç, –Ω–æ –Ω–µ —Å—Ç–µ–Ω–¥–∞–ø.
    # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ desc_match, —Ç–æ–∂–µ —Å—Ç–æ–∏—Ç –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–µ–µ.
    # –ü–æ–∫–∞ –æ—Å—Ç–∞–≤–∏–º —Ç–∞–∫: –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—å –æ–¥–∏–Ω –∏–∑ desc_match, genre_match, place_name_match (–∏ –ø—Ä–æ—à–ª–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã)
    if desc_match or genre_match:
         # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥, —á—Ç–æ–±—ã –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ —Ç–∞–∫–∏–µ —Å–ª—É—á–∞–∏
        logger.debug(f"Event '{event.name}' considered StandUp based on description/genre (desc: {desc_match}, genre: {genre_match}, place: {place_name_match})")
        return True

    return False


def _is_event_museum(event: Event) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–±—ã—Ç–∏–µ –º—É–∑–µ–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –µ–≥–æ –¥–∞–Ω–Ω—ã—Ö."""
    if not event:
        return False

    # actual_api_type - —Ç–∏–ø —Å–∞–º–æ–≥–æ "Creation" –∏–∑ API –ê—Ñ–∏—à–∏
    # event.place.Type - —Ç–∏–ø –º–µ—Å—Ç–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö /schedule (–µ—Å–ª–∏ –µ—Å—Ç—å)
    # –î–ª—è –º—É–∑–µ–µ–≤ –º—ã –º–æ–∂–µ–º –æ–∂–∏–¥–∞—Ç—å actual_api_type 'Admission' –∏–ª–∏ 'Event' (–µ—Å–ª–∏ –∏—â–µ–º –ø–æ 'Event')
    
    if event.actual_api_type not in ["Admission", "Event"]:
        logger.debug(f"Event '{event.name}' (actual_api_type: {event.actual_api_type}) is not 'Admission' or 'Event', skipping Museum check.")
        return False

    name_lower = event.name.lower()
    place_name_lower = (event.place_name or "").lower()
    description_lower = ((event.description or "") + " " + (event.short_description or "")).lower()
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    museum_keywords = [
        "–º—É–∑–µ–π", "—ç–∫—Å–ø–æ–Ω–∞", "–∫–æ–ª–ª–µ–∫—Ü–∏", "–≥–∞–ª–µ—Ä–µ", "—É—Å–∞–¥—å–±", "–¥–æ–º-–º—É–∑–µ–π", 
        "–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫", "—Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω", "–∫—Ä–∞–µ–≤–µ–¥—á–µ—Å–∫", "–≤—ã—Å—Ç–∞–≤–∫", "—ç–∫—Å–ø–æ–∑–∏—Ü–∏", # –í—ã—Å—Ç–∞–≤–∫–∏ —á–∞—Å—Ç–æ –≤ –º—É–∑–µ—è—Ö
        "–ø–∞–Ω–æ—Ä–∞–º–∞", "–¥–∏–æ—Ä–∞–º–∞", "–∞—Ä—Ö–µ–æ–ª–æ–≥–∏—á–µ—Å–∫", "–º–µ–º–æ—Ä–∏–∞–ª—å–Ω"
    ]
    # –¢–∏–ø—ã –º–µ—Å—Ç, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –º—É–∑–µ—è–º–∏
    place_type_keywords = ["–º—É–∑–µ–π", "–≥–∞–ª–µ—Ä–µ—è", "–æ–∫–µ–∞–Ω–∞—Ä–∏—É–º", "–ø–ª–∞–Ω–µ—Ç–∞—Ä–∏–π", "–≤—ã—Å—Ç–∞–≤–æ—á–Ω—ã–π –∑–∞–ª", "–ø–∞–≤–∏–ª—å–æ–Ω"]


    # 1. –ü—Ä—è–º–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Å–æ–±—ã—Ç–∏—è –∏–ª–∏ –º–µ—Å—Ç–∞
    if any(kw in name_lower for kw in museum_keywords) or \
       any(kw in place_name_lower for kw in museum_keywords) or \
       any(ptkw in place_name_lower for ptkw in place_type_keywords):
        logger.debug(f"Event '{event.name}' (Place: '{event.place_name}') considered a Museum (keyword in name/place_name).")
        return True

    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è
    if any(kw in description_lower for kw in museum_keywords):
        logger.debug(f"Event '{event.name}' considered a Museum (keyword in description).")
        return True
        
    # 3. –ï—Å–ª–∏ —Ç–∏–ø –º–µ—Å—Ç–∞ –∏–∑ API —è–≤–Ω–æ "Museum" (–ø–æ–ª–µ Place.Type –∏–∑ /schedule)
    #    –≠—Ç–æ –ø–æ–ª–µ –Ω–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –≤ –≤–∞—à–µ–π —Å—Ö–µ–º–µ Event, –Ω–æ –µ—Å–ª–∏ –±—ã –±—ã–ª–æ, –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å.
    #    –ü–æ–∫–∞ —á—Ç–æ –≤–∞—à `event.actual_api_type` - —ç—Ç–æ —Ç–∏–ø *—Å–æ–±—ã—Ç–∏—è*, –∞ –Ω–µ *–º–µ—Å—Ç–∞*.
    #    –í –ª–æ–≥–∞—Ö –º—ã –≤–∏–¥–µ–ª–∏, —á—Ç–æ "–í–æ—Ä–æ–Ω–µ–∂—Å–∫–∏–π –æ–∫–µ–∞–Ω–∞—Ä–∏—É–º" –ø—Ä–∏—Ö–æ–¥–∏–ª —Å `Place.Type: 'Museum'`
    #    –ï—Å–ª–∏ –≤—ã –¥–æ–±–∞–≤–∏—Ç–µ `place_api_type: Optional[str]` –≤ —Å—Ö–µ–º—É `Event` –∏ –±—É–¥–µ—Ç–µ –µ–≥–æ –∑–∞–ø–æ–ª–Ω—è—Ç—å
    #    –∏–∑ `schedule_block.get("Place", {}).get("Type")` –≤ `afisha_service.py`, —Ç–æ –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
    #    if event.place_api_type and event.place_api_type.lower() == "museum":
    #        logger.debug(f"Event '{event.name}' at place with API type 'Museum' considered a Museum.")
    #        return True

    logger.debug(f"Event '{event.name}' (Place: '{event.place_name}') did not pass Museum filters.")
    return False

# --- –£–∑–µ–ª 3: –ü–æ–∏—Å–∫ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π (–û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π) ---
async def search_events_node(state: AgentState) -> Dict[str, Any]:
    logger.info("Node: search_events_node executing...")
    collected_data_dict: dict = dict(state.get("collected_data", {}))
    original_user_interests_keys: List[str] = list(collected_data_dict.get("interests_keys_afisha", []))

    # –°–±—Ä–æ—Å –ø–æ–ª–µ–π –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º –Ω–æ–≤—ã–º –ø–æ–∏—Å–∫–æ–º
    collected_data_dict["not_found_interest_keys_in_primary_search"] = []
    collected_data_dict["fallback_candidates"] = {} # –°–ª–æ–≤–∞—Ä—å –¥–ª—è {interest_key: Event_Pydantic_object}
    collected_data_dict["fallback_accepted_and_plan_updated"] = False

    city_id = collected_data_dict.get("city_id_afisha")
    parsed_dates_iso_list = collected_data_dict.get("parsed_dates_iso")
    budget = collected_data_dict.get("budget_current_search")

    if not city_id or not parsed_dates_iso_list or not original_user_interests_keys:
        logger.warning(f"search_events_node: Missing critical data. City: {city_id}, Dates: {parsed_dates_iso_list}, Interests: {original_user_interests_keys}")
        # –ó–∞–ø–æ–ª–Ω—è–µ–º not_found_interest_keys_in_primary_search –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º–∏, –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏
        collected_data_dict["not_found_interest_keys_in_primary_search"] = list(original_user_interests_keys) if original_user_interests_keys else list(collected_data_dict.get("interests_original",[]))
        return {"current_events": [], "is_initial_plan_proposed": False, "collected_data": collected_data_dict}

    try:
        user_min_start_dt_naive = datetime.fromisoformat(parsed_dates_iso_list[0])
        api_date_from_dt = user_min_start_dt_naive.replace(hour=0, minute=0, second=0, microsecond=0)
        
        user_max_overall_end_dt_naive: Optional[datetime] = None
        parsed_end_dates_iso_list = collected_data_dict.get("parsed_end_dates_iso")
        if parsed_end_dates_iso_list and parsed_end_dates_iso_list[0]:
            temp_end_dt = datetime.fromisoformat(parsed_end_dates_iso_list[0])
            # –ï—Å–ª–∏ –≤—Ä–µ–º—è –Ω–µ —É–∫–∞–∑–∞–Ω–æ (00:00), —Ç–æ —Å—á–∏—Ç–∞–µ–º –¥–æ –∫–æ–Ω—Ü–∞ –¥–Ω—è
            user_max_overall_end_dt_naive = temp_end_dt.replace(hour=23, minute=59, second=59) if temp_end_dt.hour == 0 and temp_end_dt.minute == 0 else temp_end_dt
        
        # –î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –¥–ª—è API –ê—Ñ–∏—à–∏ (–≤—Å–µ–≥–¥–∞ +1 –¥–µ–Ω—å –æ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–π –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–µ–π –¥–∞—Ç—ã, –≤—Ä–µ–º—è 00:00)
        api_date_to_for_primary_search_dt = (user_max_overall_end_dt_naive or api_date_from_dt).replace(hour=0, minute=0, second=0, microsecond=0) + timedelta(days=1)
    except Exception as e_date_parse:
        logger.error(f"Error parsing dates in search_events_node: {e_date_parse}", exc_info=True)
        collected_data_dict["not_found_interest_keys_in_primary_search"] = list(original_user_interests_keys)
        return {"current_events": [], "is_initial_plan_proposed": False, "collected_data": collected_data_dict}

    min_start_for_primary_search: Optional[datetime] = None
    # –ï—Å–ª–∏ –≤ user_min_start_dt_naive –≤—Ä–µ–º—è –Ω–µ 00:00, –∑–Ω–∞—á–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∫–∞–∑–∞–ª –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞
    if not (user_min_start_dt_naive.hour == 0 and user_min_start_dt_naive.minute == 0):
        min_start_for_primary_search = user_min_start_dt_naive
    
    # max_start_for_primary_search - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –í–†–ï–ú–Ø –ù–ê–ß–ê–õ–ê —Å–æ–±—ã—Ç–∏—è –≤ —Ä–∞–º–∫–∞—Ö –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–µ–≥–æ –¥–Ω—è/–¥–∏–∞–ø–∞–∑–æ–Ω–∞
    # –ï—Å–ª–∏ user_max_overall_end_dt_naive –Ω–µ None, —Ç–æ —ç—Ç–æ –∏ –µ—Å—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ.
    # –ò–Ω–∞—á–µ, –µ—Å–ª–∏ –∏—â–µ–º –Ω–∞ –æ–¥–∏–Ω –¥–µ–Ω—å –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –æ–∫–æ–Ω—á–∞–Ω–∏—è, —Ç–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ max_start_time –Ω–µ—Ç.
    max_start_for_primary_search = user_max_overall_end_dt_naive 

    # --- –®–∞–≥ 1: –ü–µ—Ä–≤–∏—á–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫–∞–∂–¥–æ–º—É –∏–Ω—Ç–µ—Ä–µ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ---
    all_events_found_by_type_primary: Dict[str, List[Event]] = {} # {interest_key: [Event, ...]}
    
    primary_search_tasks = []
    for interest_key in original_user_interests_keys:
        task = _fetch_events_via_tool_for_interest( # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è —É–∂–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç List[Event]
            internal_key=interest_key,
            city_id=city_id,
            api_date_from_dt=api_date_from_dt,
            api_date_to_dt=api_date_to_for_primary_search_dt,
            min_start_event_time_filter=min_start_for_primary_search,
            max_start_event_time_filter=max_start_for_primary_search,
            budget=budget,
            user_max_overall_end_dt_naive_plan=user_max_overall_end_dt_naive # –î–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –û–ö–û–ù–ß–ê–ù–ò–Ø —Å–æ–±—ã—Ç–∏—è
        )
        primary_search_tasks.append(task)
    
    results_of_primary_searches: List[List[Event]] = await asyncio.gather(*primary_search_tasks, return_exceptions=True)

    for i, internal_key in enumerate(original_user_interests_keys):
        result_list_or_exc = results_of_primary_searches[i]
        if isinstance(result_list_or_exc, Exception):
            logger.error(f"Exception during primary search for interest_key='{internal_key}': {result_list_or_exc}")
            all_events_found_by_type_primary[internal_key] = []
        elif result_list_or_exc: # result_list_or_exc —ç—Ç–æ List[Event]
            all_events_found_by_type_primary[internal_key] = result_list_or_exc # –£–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ _fetch_...
        else:
            all_events_found_by_type_primary[internal_key] = []

    # --- –®–∞–≥ 2: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –≤—ã–±–æ—Ä –ª—É—á—à–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ ---
    events_to_propose: List[Event] = []
    proposed_session_ids: Set[int] = set() # –ß—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–¥–ª–∞–≥–∞—Ç—å –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ —Å–æ–±—ã—Ç–∏–µ (—Å–µ–∞–Ω—Å) –¥–≤–∞–∂–¥—ã

    for internal_interest_key in original_user_interests_keys:
        candidate_events_for_key: List[Event] = all_events_found_by_type_primary.get(internal_interest_key, [])
        
        if not candidate_events_for_key:
            logger.info(f"No API results for internal_interest_key='{internal_interest_key}' to perform post-filtering.")
            if internal_interest_key not in collected_data_dict["not_found_interest_keys_in_primary_search"]:
                 collected_data_dict["not_found_interest_keys_in_primary_search"].append(internal_interest_key)
            continue

        logger.debug(f"Post-filtering for internal_interest_key='{internal_interest_key}' with {len(candidate_events_for_key)} candidates.")
        best_event_for_this_key: Optional[Event] = None

        if internal_interest_key == "Museum":
            for event_candidate in candidate_events_for_key:
                if event_candidate.session_id in proposed_session_ids: continue
                if _is_event_museum(event_candidate):
                    best_event_for_this_key = event_candidate
                    break
        
        elif internal_interest_key == "StandUp":
            for event_candidate in candidate_events_for_key:
                if event_candidate.session_id in proposed_session_ids: continue
                if _is_event_standup(event_candidate):
                    best_event_for_this_key = event_candidate
                    break
        
        # –î–æ–±–∞–≤—å—Ç–µ elif –¥–ª—è –¥—Ä—É–≥–∏—Ö "—Å–ª–æ–∂–Ω—ã—Ö" –∫–∞—Ç–µ–≥–æ—Ä–∏–π (Exhibition, Festival, etc.)
        # –∏—Å–ø–æ–ª—å–∑—É—è –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏-—Ñ–∏–ª—å—Ç—Ä—ã _is_event_exhibition, _is_event_festival

        else: # –î–ª—è "–ø—Ä–æ—Å—Ç—ã—Ö" –∫–∞—Ç–µ–≥–æ—Ä–∏–π, –≥–¥–µ —Ç–∏–ø API –æ–±—ã—á–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–∞–¥–µ–∂–µ–Ω (Movie, Concert (–Ω–µ —Å—Ç–µ–Ω–¥–∞–ø!), Performance (—Ç–µ–∞—Ç—Ä))
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥—É—é –ø—Ä–æ–≤–µ—Ä–∫—É event.actual_api_type, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
            # –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è "Concert" (–µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å—Ç–µ–Ω–¥–∞–ø) –º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ —ç—Ç–æ –Ω–µ "Humor" –∂–∞–Ω—Ä
            # –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å—Ç–µ–Ω–¥–∞–ø–∞, –µ—Å–ª–∏ "StandUp" —Ç–æ–∂–µ –º–∞–ø–∏—Ç—Å—è –Ω–∞ "Concert".
            # –°–µ–π—á–∞—Å –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–≥–æ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ.
            
            expected_api_type: Optional[str] = None
            # –ü—Ä–∏–º–µ—Ä: –µ—Å–ª–∏ "Concert" –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏ –¥–ª—è –æ–±—ã—á–Ω—ã—Ö –∫–æ–Ω—Ü–µ—Ä—Ç–æ–≤, –∏ –¥–ª—è —Å—Ç–µ–Ω–¥–∞–ø–æ–≤,
            # —Ç–æ –∑–¥–µ—Å—å –º—ã –±—ã —Ö–æ—Ç–µ–ª–∏ –æ—Ç–æ–±—Ä–∞—Ç—å "Concert", –∫–æ—Ç–æ—Ä—ã–π –ù–ï —Å—Ç–µ–Ω–¥–∞–ø.
            if internal_interest_key == "Concert": # –≠—Ç–æ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å "–æ–±—ã—á–Ω—ã–π" –∫–æ–Ω—Ü–µ—Ä—Ç
                expected_api_type = "Concert"
                for event_candidate in candidate_events_for_key:
                    if event_candidate.session_id in proposed_session_ids: continue
                    if event_candidate.actual_api_type == expected_api_type and not _is_event_standup(event_candidate): # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —ç—Ç–æ –Ω–µ —Å—Ç–µ–Ω–¥–∞–ø
                        best_event_for_this_key = event_candidate
                        break
            elif internal_interest_key == "Performance": # –û–∂–∏–¥–∞–µ–º —Ç–µ–∞—Ç—Ä/–æ–ø–µ—Ä—É/–±–∞–ª–µ—Ç
                 expected_api_type = "Performance"
                 for event_candidate in candidate_events_for_key:
                    if event_candidate.session_id in proposed_session_ids: continue
                    # –ó–¥–µ—Å—å —Ç–æ–∂–µ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏—Å–∫–ª—é—á–∞—é—â—É—é –ª–æ–≥–∏–∫—É, –µ—Å–ª–∏ "Performance" –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å—Ç–µ–Ω–¥–∞–ø–æ–≤
                    if event_candidate.actual_api_type == expected_api_type and not _is_event_standup(event_candidate):
                        best_event_for_this_key = event_candidate
                        break
            # –î–æ–±–∞–≤—å—Ç–µ –¥—Ä—É–≥–∏–µ "–ø—Ä–æ—Å—Ç—ã–µ" –∫–ª—é—á–∏
            # ...

            if not best_event_for_this_key and candidate_events_for_key: # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ —Å—Ç—Ä–æ–≥–∏–º –ø—Ä–∞–≤–∏–ª–∞–º, –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–≥–æ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ
                for event_candidate in candidate_events_for_key:
                    if event_candidate.session_id not in proposed_session_ids:
                        # –î–ª—è "–ø—Ä–æ—Å—Ç—ã—Ö" —Ç–∏–ø–æ–≤ –º–æ–∂–Ω–æ —Ç–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ actual_api_type —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–º—É
                        # –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è "Movie" -> event_candidate.actual_api_type == "Movie"
                        # –ù–æ —ç—Ç–æ —É–∂–µ –¥–æ–ª–∂–Ω–æ –±—ã–ª–æ –±—ã—Ç—å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –≤ afisha_service –ø–æ CreationType
                        best_event_for_this_key = event_candidate
                        logger.info(f"Taking first available for simple key '{internal_interest_key}': {best_event_for_this_key.name}")
                        break
        
        if best_event_for_this_key:
            logger.info(f"Selected event '{best_event_for_this_key.name}' (ID: {best_event_for_this_key.session_id}, Actual API type: {best_event_for_this_key.actual_api_type}) for internal_interest_key='{internal_interest_key}'.")
            events_to_propose.append(best_event_for_this_key)
            proposed_session_ids.add(best_event_for_this_key.session_id)
        else:
            logger.info(f"No suitable event found for internal_interest_key='{internal_interest_key}' after primary search post-filtering.")
            if internal_interest_key not in collected_data_dict["not_found_interest_keys_in_primary_search"]:
                collected_data_dict["not_found_interest_keys_in_primary_search"].append(internal_interest_key)

    events_to_propose.sort(key=lambda e: e.start_time_naive_event_tz)

    # --- –®–∞–≥ 3: –õ–æ–≥–∏–∫–∞ Fallback –¥–ª—è –Ω–µ–Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ ---
    interests_for_fallback_search = collected_data_dict.get("not_found_interest_keys_in_primary_search", [])
    
    if interests_for_fallback_search:
        logger.info(f"Attempting fallback search for interests: {interests_for_fallback_search}")
        # –î–ª—è fallback –∏—â–µ–º –Ω–∞ –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –∏ –±–µ–∑ —Å—Ç—Ä–æ–≥–∏—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        fallback_api_date_from_dt = api_date_from_dt # –ù–∞—á–∏–Ω–∞–µ–º —Å —Ç–æ–π –∂–µ –¥–∞—Ç—ã, —á—Ç–æ –∏ –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ–∏—Å–∫
        fallback_api_date_to_dt = fallback_api_date_from_dt + timedelta(days=7) # –ù–∞ –Ω–µ–¥–µ–ª—é –≤–ø–µ—Ä–µ–¥
        
        fallback_search_tasks = []
        for interest_fb_key in interests_for_fallback_search:
            task_fb = _fetch_events_via_tool_for_interest(
                internal_key=interest_fb_key,
                city_id=city_id,
                api_date_from_dt=fallback_api_date_from_dt,
                api_date_to_dt=fallback_api_date_to_dt, 
                min_start_event_time_filter=None, # –ë–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª–∞
                max_start_event_time_filter=None, # –ë–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª–∞
                budget=budget, # –ë—é–¥–∂–µ—Ç —Å–æ—Ö—Ä–∞–Ω—è–µ–º
                user_max_overall_end_dt_naive_plan=None # –ë–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–ª–∞–Ω–∞
            )
            fallback_search_tasks.append(task_fb)
            
        results_of_fallback_searches: List[List[Event]] = await asyncio.gather(*fallback_search_tasks, return_exceptions=True)

        current_fallback_candidates: Dict[str, Event] = {} # –°–æ–±–∏—Ä–∞–µ–º –∑–¥–µ—Å—å –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é –≤ state

        for i, internal_key_fb in enumerate(interests_for_fallback_search):
            fb_event_list_or_exc = results_of_fallback_searches[i]
            
            if isinstance(fb_event_list_or_exc, Exception) or not fb_event_list_or_exc:
                logger.warning(f"Fallback search for '{internal_key_fb}' yielded no results or an error: {fb_event_list_or_exc if isinstance(fb_event_list_or_exc, Exception) else 'No results'}")
                continue
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—É –∂–µ –ø–æ—Å—Ç-—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º fallback
            best_fallback_candidate_for_key_obj: Optional[Event] = None
            
            if internal_key_fb == "Museum":
                for event_fb_candidate in fb_event_list_or_exc: # fb_event_list_or_exc —ç—Ç–æ List[Event]
                    if event_fb_candidate.session_id in proposed_session_ids: continue # –ù–µ –ø—Ä–µ–¥–ª–∞–≥–∞—Ç—å —Ç–æ, —á—Ç–æ —É–∂–µ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–ª–∞–Ω–µ
                    if _is_event_museum(event_fb_candidate):
                        best_fallback_candidate_for_key_obj = event_fb_candidate
                        break 
            elif internal_key_fb == "StandUp":
                for event_fb_candidate in fb_event_list_or_exc:
                    if event_fb_candidate.session_id in proposed_session_ids: continue
                    if _is_event_standup(event_fb_candidate):
                        best_fallback_candidate_for_key_obj = event_fb_candidate
                        break
            # –î–æ–±–∞–≤—å—Ç–µ elif –¥–ª—è –¥—Ä—É–≥–∏—Ö "—Å–ª–æ–∂–Ω—ã—Ö" –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è fallback
            else: # –î–ª—è "–ø—Ä–æ—Å—Ç—ã—Ö" –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ fallback –º–æ–∂–Ω–æ –±—ã—Ç—å –º–µ–Ω–µ–µ —Å—Ç—Ä–æ–≥–∏–º –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –≤–∑—è—Ç—å –ø–µ—Ä–≤–æ–µ
                # –ù–æ –ª—É—á—à–µ –≤—Å–µ —Ä–∞–≤–Ω–æ –∫–∞–∫—É—é-—Ç–æ –±–∞–∑–æ–≤—É—é –ø—Ä–æ–≤–µ—Ä–∫—É —Ç–∏–ø–∞ —Å–¥–µ–ª–∞—Ç—å, –µ—Å–ª–∏ —ç—Ç–æ –≤–∞–∂–Ω–æ
                if fb_event_list_or_exc: # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—å –∫–∞–∫–∏–µ-—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    for event_fb_candidate in fb_event_list_or_exc:
                        if event_fb_candidate.session_id in proposed_session_ids: continue
                        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É, –Ω–∞–ø—Ä–∏–º–µ—Ä, —á—Ç–æ CreationType –æ—Ç API —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –æ–∂–∏–¥–∞–µ–º—ã–º –¥–ª—è —ç—Ç–æ–≥–æ internal_key_fb
                        # –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ internal_key_fb == "Movie", —Ç–æ event_fb_candidate.actual_api_type == "Movie"
                        best_fallback_candidate_for_key_obj = event_fb_candidate
                        logger.info(f"Taking first available for simple fallback key '{internal_key_fb}': {best_fallback_candidate_for_key_obj.name}")
                        break

            if best_fallback_candidate_for_key_obj:
                # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —ç—Ç–æ—Ç fallback –µ—â–µ –Ω–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –∏ –Ω–µ –±—ã–ª –æ—Ç–∫–ª–æ–Ω–µ–Ω —Ä–∞–Ω–µ–µ (–µ—Å–ª–∏ –µ—Å—Ç—å —Ç–∞–∫–∞—è –ª–æ–≥–∏–∫–∞)
                # –ò —á—Ç–æ –æ–Ω –Ω–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É–µ—Ç –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å —É–∂–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ events_to_propose (–µ—Å–ª–∏ –∏—Ö >0)
                # –ü–æ–∫–∞ —á—Ç–æ –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º, –µ—Å–ª–∏ –æ–Ω —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω –ø–æ —Ç–∏–ø—É.
                if best_fallback_candidate_for_key_obj.session_id not in proposed_session_ids:
                    current_fallback_candidates[internal_key_fb] = best_fallback_candidate_for_key_obj
                    logger.info(f"Found RELEVANT fallback candidate for '{internal_key_fb}': {best_fallback_candidate_for_key_obj.name} on {best_fallback_candidate_for_key_obj.start_time_naive_event_tz.date()}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º collected_data_dict —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º–∏ fallback –∫–∞–Ω–¥–∏–¥–∞—Ç–∞–º–∏
        if current_fallback_candidates:
            collected_data_dict["fallback_candidates"] = {
                key: event.model_dump() for key, event in current_fallback_candidates.items()
            }


    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –±—ã–ª –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –Ω–∞—á–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω
    # –ü–ª–∞–Ω —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–º, –µ—Å–ª–∏ –µ—Å—Ç—å —á—Ç–æ –ø–æ–∫–∞–∑–∞—Ç—å: –ª–∏–±–æ –ø—Ä—è–º—ã–µ —Å–æ–±—ã—Ç–∏—è, –ª–∏–±–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ fallback-–∫–∞–Ω–¥–∏–¥–∞—Ç—ã
    is_initial_plan_now_proposed = bool(events_to_propose) or bool(collected_data_dict.get("fallback_candidates"))
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –Ω–µ–Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤: —Ç–æ–ª—å–∫–æ —Ç–µ, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –Ω–∏ –ø—Ä—è–º–æ–≥–æ —Å–æ–±—ã—Ç–∏—è, –Ω–∏ fallback
    final_not_found_keys = []
    if collected_data_dict.get("not_found_interest_keys_in_primary_search"):
        for key_not_found_in_primary in collected_data_dict["not_found_interest_keys_in_primary_search"]:
            is_covered_by_fallback = key_not_found_in_primary in collected_data_dict.get("fallback_candidates", {})
            is_covered_by_direct = any(event.event_type_key == key_not_found_in_primary for event in events_to_propose)
            
            if not is_covered_by_fallback and not is_covered_by_direct:
                final_not_found_keys.append(key_not_found_in_primary)
    
    collected_data_dict["not_found_interest_keys_final"] = final_not_found_keys # –ù–æ–≤–æ–µ –ø–æ–ª–µ –¥–ª—è error_node

    logger.info(
        f"search_events_node final proposal: {len(events_to_propose)} direct events. "
        f"Fallback candidates for: {list(collected_data_dict.get('fallback_candidates', {}).keys())}. "
        f"Interests truly not found (after primary and fallback filters): {final_not_found_keys}"
    )
    
    return {
        "current_events": events_to_propose, # –¢–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –ø—Ä–æ—à–ª–∏ –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        "is_initial_plan_proposed": is_initial_plan_now_proposed,
        "collected_data": collected_data_dict, # –° –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ fallback_candidates –∏ not_found_interest_keys_final
    }



async def _check_event_compatibility(
    first_event: Event,
    second_event_candidate: Event,
    user_max_overall_end_dt_naive: Optional[datetime],
) -> Tuple[bool, Optional[str]]:
    first_event_duration_minutes = first_event.duration_minutes or 120
    first_event_end_naive = first_event.start_time_naive_event_tz + timedelta(
        minutes=first_event_duration_minutes
    )

    if (
        user_max_overall_end_dt_naive
        and first_event_end_naive > user_max_overall_end_dt_naive
    ):
        return False, "–ü–µ—Ä–≤–æ–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Å–ª–∏—à–∫–æ–º –ø–æ–∑–¥–Ω–æ."
    if second_event_candidate.start_time_naive_event_tz < first_event_end_naive:
        return False, "–í—Ç–æ—Ä–æ–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –¥–æ –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ."

    route_duration_minutes = 30
    if (
        first_event.place_coords_lon
        and first_event.place_coords_lat
        and second_event_candidate.place_coords_lon
        and second_event_candidate.place_coords_lat
    ):
        try:
            route_result = await get_route(
                points=[
                    {
                        "lon": first_event.place_coords_lon,
                        "lat": first_event.place_coords_lat,
                    },
                    {
                        "lon": second_event_candidate.place_coords_lon,
                        "lat": second_event_candidate.place_coords_lat,
                    },
                ],
                transport="driving",
            )
            if route_result and route_result.get("status") == "success":
                route_duration_minutes = route_result.get("duration_seconds", 1800) / 60
            else:
                logger.warning(
                    f"Route error for compatibility check: {route_result.get('message') if route_result else 'No response'}"
                )
        except Exception as e_route:
            logger.error(
                f"get_route exception for compatibility: {e_route}", exc_info=True
            )

    arrival_at_second_event_naive = first_event_end_naive + timedelta(
        minutes=route_duration_minutes
    )
    buffer_time = timedelta(minutes=15)

    if (
        arrival_at_second_event_naive
        > second_event_candidate.start_time_naive_event_tz - buffer_time
    ):
        return False, "–ù–µ —É—Å–ø–µ—Ç—å –Ω–∞ –≤—Ç–æ—Ä–æ–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ."

    second_event_duration_minutes = second_event_candidate.duration_minutes or 120
    second_event_end_naive = (
        second_event_candidate.start_time_naive_event_tz
        + timedelta(minutes=second_event_duration_minutes)
    )
    if (
        user_max_overall_end_dt_naive
        and second_event_end_naive > user_max_overall_end_dt_naive
    ):
        return False, "–í—Ç–æ—Ä–æ–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Å–ª–∏—à–∫–æ–º –ø–æ–∑–¥–Ω–æ."
    return True, None


# --- –£–∑–µ–ª 4: –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –∏ –∑–∞–ø—Ä–æ—Å –∞–¥—Ä–µ—Å–∞/–±—é–¥–∂–µ—Ç–∞ (–û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø) ---
async def present_initial_plan_node(state: AgentState) -> Dict[str, Any]:
    logger.info("Node: present_initial_plan_node executing...")
    current_events: List[Event] = state.get(
        "current_events", []
    )  # –≠—Ç–æ —Ç–æ, —á—Ç–æ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –°–†–ê–ó–£
    collected_data_dict: dict = dict(state.get("collected_data", {}))

    response_parts = []
    awaiting_fallback_conf = False
    pending_fallback_event_for_state: Optional[Dict] = None
    field_to_be_clarified_next: Optional[str] = None

    if current_events:
        response_parts.append("–í–æ—Ç —á—Ç–æ —è —Å–º–æ–≥ –Ω–∞–π—Ç–∏ –¥–ª—è –≤–∞—Å –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É:")
        for i, event in enumerate(current_events):
            time_str = event.start_time_naive_event_tz.strftime("%H:%M")
            date_str = event.start_time_naive_event_tz.strftime("%d.%m.%Y")
            desc = f"{i+1}. **{event.name}** ({event.event_type_key}) –≤ '{event.place_name}' ({event.place_address or '–ê–¥—Ä–µ—Å –Ω–µ —É–∫–∞–∑–∞–Ω'}). –ù–∞—á–∞–ª–æ –≤ {time_str} ({date_str})."
            if event.min_price is not None:
                desc += f" –¶–µ–Ω–∞ –æ—Ç {event.min_price} —Ä—É–±."
            if event.duration_minutes:
                desc += f" –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å ~{event.duration_minutes // 60}—á {event.duration_minutes % 60}–º."
            response_parts.append(desc)

    # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º fallback –¥–ª—è —Ç–µ—Ö –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –Ω–µ –±—ã–ª–æ —Å–æ–±—ã—Ç–∏–π –≤ current_events
    # –Ω–æ –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –∑–∞–ø—Ä–æ—à–µ–Ω—ã –∏ –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å fallback-–∫–∞–Ω–¥–∏–¥–∞—Ç.
    original_user_interests_keys = collected_data_dict.get("interests_keys_afisha", [])
    fallback_candidates = collected_data_dict.get("fallback_candidates", {})
    # –ò—Å–∫–ª—é—á–∞–µ–º –∏–Ω—Ç–µ—Ä–µ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –µ—Å—Ç—å –≤ current_events
    interests_covered_by_current_events = {e.event_type_key for e in current_events}

    interest_key_to_name_map = {
        "Movie": "—Ñ–∏–ª—å–º–æ–≤",
        "Performance": "—Å–ø–µ–∫—Ç–∞–∫–ª–µ–π",
        "Concert": "–∫–æ–Ω—Ü–µ—Ä—Ç–æ–≤",
    }

    for interest_key_fb in original_user_interests_keys:
        if (
            interest_key_fb in interests_covered_by_current_events
        ):  # –£–∂–µ –µ—Å—Ç—å –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏
            continue

        fb_event_data = fallback_candidates.get(interest_key_fb)
        if fb_event_data and not collected_data_dict.get(
            "fallback_accepted_and_plan_updated"
        ):  # –ò –µ—â–µ –Ω–µ –ø—Ä–µ–¥–ª–∞–≥–∞–ª–∏/–ø—Ä–∏–Ω–∏–º–∞–ª–∏ fallback –ø–æ —ç—Ç–æ–º—É –∏–Ω—Ç–µ—Ä–µ—Å—É
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—Ä–µ–¥–ª–∞–≥–∞–ª–∏ –ª–∏ –º—ã —É–∂–µ —ç—Ç–æ—Ç fallback
            if collected_data_dict.get(
                "last_offered_fallback_for_interest"
            ) == interest_key_fb and not state.get("messages", [])[
                -1
            ].content.lower().startswith(
                "–¥–∞"
            ):  # –ï—Å–ª–∏ —É–∂–µ –ø—Ä–µ–¥–ª–∞–≥–∞–ª–∏ –∏ –æ—Ç–≤–µ—Ç –±—ã–ª –Ω–µ "–¥–∞"
                continue

            try:
                fb_event = Event(**fb_event_data)
                type_name = interest_key_to_name_map.get(
                    interest_key_fb, interest_key_fb
                )
                fb_time_str = fb_event.start_time_naive_event_tz.strftime("%H:%M")
                fb_date_str = fb_event.start_time_naive_event_tz.strftime("%d.%m.%Y")
                time_desc_orig = collected_data_dict.get(
                    "dates_description_original", "–∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è"
                )
                if collected_data_dict.get("raw_time_description_original"):
                    time_desc_orig += (
                        f" ({collected_data_dict['raw_time_description_original']})"
                    )

                fallback_msg = f"\n–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö {type_name} –Ω–∞ {time_desc_orig} –Ω–µ –Ω–∞—à–ª–æ—Å—å. "
                fallback_msg += f"–û–¥–Ω–∞–∫–æ, –µ—Å—Ç—å –¥—Ä—É–≥–æ–π –≤–∞—Ä–∏–∞–Ω—Ç: ¬´{fb_event.name}¬ª ({type_name[:-1].lower() if type_name.endswith('–æ–≤') else type_name.lower()}) –Ω–∞ {fb_date_str} –≤ {fb_time_str}"
                if fb_event.place_name:
                    fallback_msg += f" –≤ ¬´{fb_event.place_name}¬ª"
                if fb_event.min_price is not None:
                    fallback_msg += f" (—Ü–µ–Ω–∞ –æ—Ç {fb_event.min_price} —Ä—É–±.)"
                fallback_msg += ". –•–æ—Ç–∏—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –µ–≥–æ –≤ –ø–ª–∞–Ω? (–¥–∞/–Ω–µ—Ç)"
                response_parts.append(fallback_msg)

                awaiting_fallback_conf = True
                pending_fallback_event_for_state = fb_event.model_dump()
                collected_data_dict["last_offered_fallback_for_interest"] = (
                    interest_key_fb
                )
                break
            except ValidationError as e:
                logger.error(
                    f"Error validating fallback event {fb_event_data.get('name')}: {e}"
                )

    # –°–æ–æ–±—â–µ–Ω–∏–µ –æ –Ω–µ–Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–µ—Å–∞—Ö (–µ—Å–ª–∏ –ø–æ –Ω–∏–º –Ω–µ—Ç –Ω–∏ current_event, –Ω–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–æ–≥–æ fallback)
    if not awaiting_fallback_conf:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –∂–¥–µ–º –æ—Ç–≤–µ—Ç–∞ –ø–æ fallback
        truly_not_found_keys = []
        for key in original_user_interests_keys:
            if (
                key not in interests_covered_by_current_events
                and key not in fallback_candidates
            ):
                truly_not_found_keys.append(interest_key_to_name_map.get(key, key))

        if truly_not_found_keys:
            if not current_events:  # –ï—Å–ª–∏ –∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π –Ω–µ—Ç
                response_parts = [
                    f"–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ {', '.join(truly_not_found_keys)} –ø–æ –≤–∞—à–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º."
                ]
            else:
                response_parts.append(
                    f"\n–¢–∞–∫–∂–µ –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ {', '.join(truly_not_found_keys)}."
                )

    if awaiting_fallback_conf:
        collected_data_dict["awaiting_fallback_confirmation"] = True
        collected_data_dict["pending_fallback_event"] = pending_fallback_event_for_state
    else:
        if "awaiting_fallback_confirmation" in collected_data_dict:
            del collected_data_dict["awaiting_fallback_confirmation"]
        if "pending_fallback_event" in collected_data_dict:
            del collected_data_dict["pending_fallback_event"]
        if "last_offered_fallback_for_interest" in collected_data_dict:
            del collected_data_dict["last_offered_fallback_for_interest"]

        questions_to_user = []
        if not collected_data_dict.get(
            "user_start_address_original"
        ) and not collected_data_dict.get("user_start_address_validated_coords"):
            if current_events or collected_data_dict.get(
                "fallback_accepted_and_plan_updated"
            ):  # –ï—Å–ª–∏ –µ—Å—Ç—å —á—Ç–æ-—Ç–æ –≤ –ø–ª–∞–Ω–µ
                questions_to_user.append(
                    "–û—Ç–∫—É–¥–∞ –≤—ã –ø–ª–∞–Ω–∏—Ä—É–µ—Ç–µ –Ω–∞—á–∞—Ç—å –º–∞—Ä—à—Ä—É—Ç? –ù–∞–∑–æ–≤–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∞–¥—Ä–µ—Å (—É–ª–∏—Ü–∞ –∏ –¥–æ–º)."
                )
                field_to_be_clarified_next = "user_start_address_original"

        # –ë—é–¥–∂–µ—Ç –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –∏ –Ω–µ —Å–ø—Ä–∞—à–∏–≤–∞–µ–º –∞–¥—Ä–µ—Å
        if (
            collected_data_dict.get("budget_original") is None
        ):  # –ò—Å–ø–æ–ª—å–∑—É–µ–º budget_original –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, –±—ã–ª –ª–∏ –æ–Ω —É–∫–∞–∑–∞–Ω
            if not field_to_be_clarified_next:
                questions_to_user.append("–£—Ç–æ—á–Ω–∏—Ç–µ –≤–∞—à –±—é–¥–∂–µ—Ç –Ω–∞ –æ–¥–Ω–æ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ?")
                field_to_be_clarified_next = "budget_original"

        if questions_to_user:
            current_plan_text = "\n".join(filter(None, response_parts))
            if current_plan_text.strip() and not current_plan_text.startswith(
                "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏"
            ):
                final_msg_text = (
                    current_plan_text + "\n\n" + " ".join(questions_to_user)
                )
            else:  # –ï—Å–ª–∏ —Å–æ–±—ã—Ç–∏–π –Ω–µ—Ç –∏–ª–∏ —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ, –∞ –ø–æ—Ç–æ–º –≤–æ–ø—Ä–æ—Å—ã
                if (
                    not current_plan_text.strip() and not current_events
                ):  # –ï—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ –±—ã–ª–æ
                    final_msg_text = " ".join(questions_to_user)
                else:  # –ï—Å–ª–∏ –±—ã–ª–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
                    final_msg_text = (
                        current_plan_text + "\n" + " ".join(questions_to_user)
                    )

            response_parts = [final_msg_text]
        elif current_events:
            response_parts.append(
                "\n\n–ö–∞–∫ –≤–∞–º —Ç–∞–∫–æ–π –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø–ª–∞–Ω? –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç, —Å–∫–∞–∂–∏—Ç–µ, –ø–æ–ø—Ä–æ–±—É–µ–º –∏–∑–º–µ–Ω–∏—Ç—å."
            )
        elif (
            not current_events
            and not awaiting_fallback_conf
            and not ("".join(response_parts)).strip()
        ):
            response_parts = [
                "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏?"
            ]
            field_to_be_clarified_next = None

    if "fallback_accepted_and_plan_updated" in collected_data_dict:
        del collected_data_dict[
            "fallback_accepted_and_plan_updated"
        ]  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

    final_response_text = ("\n".join(filter(None, response_parts))).strip()
    if not final_response_text:
        final_response_text = (
            "–ü–ª–∞–Ω –≥–æ—Ç–æ–≤. –ß—Ç–æ-–Ω–∏–±—É–¥—å –µ—â–µ?"
            if current_events
            else "–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏?"
        )

    new_messages = state.get("messages", []) + [AIMessage(content=final_response_text)]

    return {
        "messages": new_messages,
        "status_message_to_user": final_response_text,
        "collected_data": collected_data_dict,
        "is_initial_plan_proposed": bool(current_events)
        and not awaiting_fallback_conf,  # –ü–ª–∞–Ω –ø—Ä–µ–¥–ª–æ–∂–µ–Ω, –µ—Å–ª–∏ –µ—Å—Ç—å —Å–æ–±—ã—Ç–∏—è –∏ –Ω–µ –∂–¥–µ–º –æ—Ç–≤–µ—Ç–∞ –Ω–∞ fallback
        "awaiting_final_confirmation": False,
        "awaiting_clarification_for_field": field_to_be_clarified_next,
    }


# --- –£–∑–µ–ª 5: –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –∞–¥—Ä–µ—Å –ò–õ–ò –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ä—à—Ä—É—Ç–∞, –µ—Å–ª–∏ –∞–¥—Ä–µ—Å –Ω–µ –Ω—É–∂–µ–Ω / —É–∂–µ –µ—Å—Ç—å ---
async def clarify_address_or_build_route_node(state: AgentState) -> Dict[str, Any]:
    logger.info("Node: clarify_address_or_build_route_node executing...")
    collected_data: CollectedUserData = state.get("collected_data", {})  # type: ignore
    current_events: List[Event] = state.get("current_events", [])  # type: ignore

    if not current_events:
        logger.warning("build_route_node: No current events for route.")
        return {
            "current_route_details": RouteDetails(
                status="error", error_message="–ù–µ—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π."
            ),
            "is_full_plan_with_route_proposed": False,
        }

    user_start_address_str = collected_data.get("user_start_address_original")
    user_start_coords = collected_data.get("user_start_address_validated_coords")

    if (
        not user_start_coords
    ):  # –ï—Å–ª–∏ –∞–¥—Ä–µ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ—Ç, –º–∞—Ä—à—Ä—É—Ç –Ω–µ —Å—Ç—Ä–æ–∏–º (–∏–ª–∏ —Å—Ç—Ä–æ–∏–º —Ç–æ–ª—å–∫–æ –º–µ–∂–¥—É —Å–æ–±—ã—Ç–∏—è–º–∏, –µ—Å–ª–∏ –∏—Ö > 1)
        if len(current_events) > 1:
            logger.info(
                "User address not provided, will attempt route between events if possible."
            )
            # –î–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ –º–µ–∂–¥—É —Å–æ–±—ã—Ç–∏—è–º–∏, start_point –±—É–¥–µ—Ç –ø–µ—Ä–≤—ã–º —Å–æ–±—ã—Ç–∏–µ–º
            # –≠—Ç–∞ –ª–æ–≥–∏–∫–∞ —É–∂–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ RouteBuilderToolArgs –∏–ª–∏ –∑–¥–µ—Å—å
        else:  # –û–¥–Ω–æ —Å–æ–±—ã—Ç–∏–µ –∏ –Ω–µ—Ç –∞–¥—Ä–µ—Å–∞
            logger.info("One event and no user address, no route to build from user.")
            return {"current_route_details": None, "is_full_plan_with_route_proposed": False}  # type: ignore

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å–µ –ª–∏ —Å–æ–±—ã—Ç–∏—è –≤ –æ–¥–∏–Ω –¥–µ–Ω—å
    event_dates: Set[date] = {
        evt.start_time_naive_event_tz.date() for evt in current_events
    }
    multiple_days = len(event_dates) > 1

    logger.info(f"Route for events on multiple_days: {multiple_days}")

    all_route_segments: List[RouteSegment] = []
    total_duration_seconds_combined = 0
    total_distance_meters_combined = 0
    overall_route_status = "success"

    if multiple_days:
        if not user_start_coords:  # –ù—É–∂–µ–Ω –∞–¥—Ä–µ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–æ–≤ –≤ —Ä–∞–∑–Ω—ã–µ –¥–Ω–∏
            logger.warning("Multiple day events but no user start address for routing.")
            return {
                "current_route_details": RouteDetails(
                    status="error",
                    error_message="–î–ª—è –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –≤ —Ä–∞–∑–Ω—ã–µ –¥–Ω–∏ –Ω—É–∂–µ–Ω –≤–∞—à –∞–¥—Ä–µ—Å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è.",
                ),
                "is_full_plan_with_route_proposed": False,
            }

        user_start_location = LocationModel(lon=user_start_coords["lon"], lat=user_start_coords["lat"], address_string=user_start_address_str)  # type: ignore

        for i, event_obj in enumerate(current_events):
            event_location = None
            if (
                event_obj.place_coords_lon is not None
                and event_obj.place_coords_lat is not None
            ):
                event_location = LocationModel(
                    lon=event_obj.place_coords_lon,
                    lat=event_obj.place_coords_lat,
                    address_string=event_obj.place_address,
                )
            elif event_obj.place_address:
                coords = await get_coords_from_address(address=event_obj.place_address, city=collected_data.get("city_name", ""))  # type: ignore
                if coords:
                    event_location = LocationModel(
                        lon=coords[0],
                        lat=coords[1],
                        address_string=event_obj.place_address,
                    )

            if not event_location:
                logger.warning(
                    f"Could not get location for event {event_obj.name} for multi-day route."
                )
                segment_error = RouteSegment(
                    from_address=user_start_address_str or "–í–∞—à–µ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ",
                    to_address=event_obj.name,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è —Å–æ–±—ã—Ç–∏—è –∫–∞–∫ to_address
                    segment_status="error",
                    segment_error_message=f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è '{event_obj.name}'",
                )
                all_route_segments.append(segment_error)
                overall_route_status = "partial_success"
                continue

            tool_args_segment = RouteBuilderToolArgs(
                start_point=user_start_location, event_points=[event_location]
            )
            logger.info(
                f"Building route from User to Event {i+1} ({event_obj.name}): {tool_args_segment.model_dump_json(exclude_none=True)}"
            )
            route_data_segment_dict = await route_builder_tool.ainvoke(
                tool_args_segment.model_dump(exclude_none=True)
            )
            try:
                route_details_segment = RouteDetails(**route_data_segment_dict)
                if (
                    route_details_segment.status == "success"
                    and route_details_segment.segments
                ):
                    all_route_segments.extend(route_details_segment.segments)
                    total_duration_seconds_combined += (
                        route_details_segment.total_duration_seconds or 0
                    )
                    total_distance_meters_combined += (
                        route_details_segment.total_distance_meters or 0
                    )
                else:
                    overall_route_status = "partial_success"
                    error_msg_seg = (
                        route_details_segment.error_message
                        or f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ä—à—Ä—É—Ç –¥–æ '{event_obj.name}'"
                    )
                    all_route_segments.append(
                        RouteSegment(
                            from_address=user_start_address_str,
                            to_address=event_obj.place_address or event_obj.name,
                            segment_status="error",
                            segment_error_message=error_msg_seg,
                        )
                    )
            except ValidationError:
                overall_route_status = "partial_success"
                all_route_segments.append(
                    RouteSegment(
                        from_address=user_start_address_str,
                        to_address=event_obj.place_address or event_obj.name,
                        segment_status="error",
                        segment_error_message="–û—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö –º–∞—Ä—à—Ä—É—Ç–∞",
                    )
                )

    else:  # –í—Å–µ —Å–æ–±—ã—Ç–∏—è –≤ –æ–¥–∏–Ω –¥–µ–Ω—å - —Å—Ç—Ä–æ–∏–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç
        start_location_for_api: Optional[LocationModel] = None
        event_points_for_api: List[LocationModel] = []

        if user_start_coords:
            start_location_for_api = LocationModel(lon=user_start_coords["lon"], lat=user_start_coords["lat"], address_string=user_start_address_str)  # type: ignore
            target_events_for_route = current_events
        elif len(current_events) > 1:  # –ù–µ—Ç –∞–¥—Ä–µ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –Ω–æ –µ—Å—Ç—å >1 —Å–æ–±—ã—Ç–∏—è
            first_event = current_events[0]
            if (
                first_event.place_coords_lon is not None
                and first_event.place_coords_lat is not None
            ):
                start_location_for_api = LocationModel(
                    lon=first_event.place_coords_lon,
                    lat=first_event.place_coords_lat,
                    address_string=first_event.place_address,
                )
            # ... (–≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ —Å–æ–±—ã—Ç–∏—è, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ, –∫–∞–∫ –≤ –≤–∞—à–µ–º —Å—Ç–∞—Ä–æ–º –∫–æ–¥–µ) ...
            target_events_for_route = current_events[1:]
        else:  # –û–¥–Ω–æ —Å–æ–±—ã—Ç–∏–µ, –Ω–µ—Ç –∞–¥—Ä–µ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤—ã—à–µ
            return {"current_route_details": None, "is_full_plan_with_route_proposed": False}  # type: ignore

        if not start_location_for_api:  # –ï—Å–ª–∏ —Å—Ç–∞—Ä—Ç–æ–≤–∞—è —Ç–æ—á–∫–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∞—Å—å
            return {
                "current_route_details": RouteDetails(
                    status="error",
                    error_message="–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞—á–∞–ª—å–Ω—É—é —Ç–æ—á–∫—É –º–∞—Ä—à—Ä—É—Ç–∞.",
                ),
                "is_full_plan_with_route_proposed": False,
            }

        for event_obj in target_events_for_route:
            # ... (–ª–æ–≥–∏–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è event_obj –≤ event_points_for_api —Å –≥–µ–æ–∫–æ–¥–∏–Ω–≥–æ–º, –∫–∞–∫ –≤ –≤–∞—à–µ–º —Å—Ç–∞—Ä–æ–º –∫–æ–¥–µ) ...
            if (
                event_obj.place_coords_lon is not None
                and event_obj.place_coords_lat is not None
            ):
                event_points_for_api.append(
                    LocationModel(
                        lon=event_obj.place_coords_lon,
                        lat=event_obj.place_coords_lat,
                        address_string=event_obj.place_address,
                    )
                )
            # ... (else —Å –≥–µ–æ–∫–æ–¥–∏–Ω–≥–æ–º)

        if (
            not event_points_for_api and target_events_for_route
        ):  # –ï—Å–ª–∏ –µ—Å—Ç—å –∫ —á–µ–º—É —Å—Ç—Ä–æ–∏—Ç—å, –Ω–æ –Ω–µ —Å–º–æ–≥–ª–∏ –ø–æ–ª—É—á–∏—Ç—å —Ç–æ—á–∫–∏
            return {
                "current_route_details": RouteDetails(
                    status="error",
                    error_message="–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–æ–±—ã—Ç–∏–π –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞.",
                ),
                "is_full_plan_with_route_proposed": False,
            }

        if event_points_for_api:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –∫—É–¥–∞ —Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ä—à—Ä—É—Ç
            tool_args_single_day = RouteBuilderToolArgs(
                start_point=start_location_for_api, event_points=event_points_for_api
            )
            logger.info(
                f"Building single-day route: {tool_args_single_day.model_dump_json(exclude_none=True)}"
            )
            route_data_dict = await route_builder_tool.ainvoke(
                tool_args_single_day.model_dump(exclude_none=True)
            )
            try:
                single_day_route_details = RouteDetails(**route_data_dict)
                all_route_segments = single_day_route_details.segments or []
                total_duration_seconds_combined = (
                    single_day_route_details.total_duration_seconds or 0
                )
                total_distance_meters_combined = (
                    single_day_route_details.total_distance_meters or 0
                )
                overall_route_status = single_day_route_details.status
                if (
                    single_day_route_details.status != "success"
                    and single_day_route_details.error_message
                ):
                    logger.error(
                        f"Single-day route error: {single_day_route_details.error_message}"
                    )  # –î–æ–ø. –ª–æ–≥

            except ValidationError as ve:
                logger.error(f"Validation error for single-day route data: {ve}")
                overall_route_status = "error"
                all_route_segments.append(
                    RouteSegment(
                        segment_status="error",
                        segment_error_message="–û—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö –º–∞—Ä—à—Ä—É—Ç–∞",
                    )
                )
        elif (
            not event_points_for_api and user_start_coords and len(current_events) == 1
        ):  # –ú–∞—Ä—à—Ä—É—Ç –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–æ –æ–¥–Ω–æ–≥–æ —Å–æ–±—ã—Ç–∏—è
            # –≠—Ç–∞ –ª–æ–≥–∏–∫–∞ –ø–æ–∫—Ä—ã–≤–∞–µ—Ç—Å—è multiple_days = False –∏ target_events_for_route = current_events
            # –µ—Å–ª–∏ start_location_for_api —ç—Ç–æ —é–∑–µ—Ä, –∞ event_points_for_api —ç—Ç–æ –æ–¥–Ω–æ —Å–æ–±—ã—Ç–∏–µ.
            pass  # –£–∂–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤—ã—à–µ
        elif (
            not event_points_for_api
        ):  # –ï—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–µ –∫ —á–µ–º—É —Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ä—à—Ä—É—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–¥–Ω–æ —Å–æ–±—ã—Ç–∏–µ –±–µ–∑ –∞–¥—Ä–µ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
            return {"current_route_details": None, "is_full_plan_with_route_proposed": False}  # type: ignore

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π RouteDetails
    final_route_details = RouteDetails(
        status=overall_route_status,
        segments=all_route_segments,
        total_duration_seconds=total_duration_seconds_combined,
        total_distance_meters=total_distance_meters_combined,
        total_duration_text=(
            f"~{round(total_duration_seconds_combined / 60)} –º–∏–Ω"
            if total_duration_seconds_combined
            else None
        ),
        total_distance_text=(
            f"~{round(total_distance_meters_combined / 1000, 1)} –∫–º"
            if total_distance_meters_combined
            else None
        ),
        error_message=(
            "–û–¥–Ω–∞ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–µ–π –º–∞—Ä—à—Ä—É—Ç–∞ –Ω–µ –º–æ–≥–ª–∏ –±—ã—Ç—å –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã."
            if overall_route_status == "partial_success"
            else (
                "–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–∞—Ä—à—Ä—É—Ç–∞."
                if overall_route_status == "error"
                else None
            )
        ),
    )

    return {
        "current_route_details": final_route_details,
        "is_full_plan_with_route_proposed": final_route_details.status
        in ["success", "partial_success"]
        and bool(final_route_details.segments),
    }


# --- –£–∑–µ–ª 6: –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ (–º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è + –º–∞—Ä—à—Ä—É—Ç) ---
async def present_full_plan_node(state: AgentState) -> Dict[str, Any]:
    logger.info("Node: present_full_plan_node executing...")
    current_events: List[Event] = state.get("current_events", [])  # type: ignore
    current_route_details_obj: Optional[RouteDetails] = state.get("current_route_details")  # type: ignore
    collected_data: CollectedUserData = dict(state.get("collected_data", {}))  # type: ignore

    # not_found_interest_keys –∏ fallback_candidates —É–∂–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã present_initial_plan_node
    # –∏–ª–∏ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ fallback. –ó–¥–µ—Å—å –º—ã –ø—Ä–æ—Å—Ç–æ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–æ, —á—Ç–æ –µ—Å—Ç—å –≤ current_events –∏ current_route_details.

    if not current_events:
        # –≠—Ç–∞ —Å–∏—Ç—É–∞—Ü–∏—è –º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω–∞, –µ—Å–ª–∏ –≥—Ä–∞—Ñ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ, —Ç.–∫. –¥–æ —ç—Ç–æ–≥–æ —É–∑–ª–∞ –¥–æ–ª–∂–Ω—ã –¥–æ–π—Ç–∏ —Ç–æ–ª—å–∫–æ —Å —Å–æ–±—ã—Ç–∏—è–º–∏.
        logger.warning("present_full_plan_node: No current events to present.")
        return {
            "status_message_to_user": "–ú–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏—Ç–µ –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫."
        }

    response_parts = ["–í–æ—Ç –≤–∞—à –∏—Ç–æ–≥–æ–≤—ã–π –ø–ª–∞–Ω:"]
    # ... (–æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π, –∫–∞–∫ –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤–∞—à–µ–π –≤–µ—Ä—Å–∏–∏)
    for i, event in enumerate(current_events):
        event_time_str = event.start_time_naive_event_tz.strftime("%H:%M")
        event_date_str = event.start_time_naive_event_tz.strftime(
            "%d.%m.%Y (%A)"
        )  # –î–æ–±–∞–≤–∏–ª –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏
        desc = f"\n{i+1}. **{event.name}** ({event.event_type_key})\n   *–ú–µ—Å—Ç–æ:* {event.place_name} ({event.place_address or '–ê–¥—Ä–µ—Å –Ω–µ —É—Ç–æ—á–Ω–µ–Ω'})"
        desc += f"\n   *–í—Ä–µ–º—è:* {event_date_str} –≤ {event_time_str}"
        if event.duration_minutes:
            desc += f" (–ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å ~{event.duration_minutes // 60}—á {event.duration_minutes % 60}–º)"
        if event.price_text:
            desc += f"\n   *–¶–µ–Ω–∞:* {event.price_text}"
        elif event.min_price is not None:
            desc += f"\n   *–¶–µ–Ω–∞:* –æ—Ç {event.min_price} —Ä—É–±."
        response_parts.append(desc)

    event_dates_set: Set[date] = {
        evt.start_time_naive_event_tz.date() for evt in current_events
    }
    multiple_days = len(event_dates_set) > 1

    if current_route_details_obj:
        if (
            current_route_details_obj.status in ["success", "partial_success"]
            and current_route_details_obj.segments
        ):
            response_parts.append("\n–ú–∞—Ä—à—Ä—É—Ç:")
            if multiple_days:
                response_parts.append(
                    "  (–ú–∞—Ä—à—Ä—É—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–Ω—è –æ—Ç –≤–∞—à–µ–≥–æ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è)"
                )

            for idx, segment in enumerate(current_route_details_obj.segments):
                from_name = segment.from_address or (
                    f"–í–∞—à–µ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ" if multiple_days else f"–¢–æ—á–∫–∞ {idx+1}"
                )
                to_name = (
                    segment.to_address
                    or f"–ú–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ {idx+1 if not multiple_days else ''}"
                )  # –£—Ç–æ—á–Ω–∏—Ç—å –∏–º—è —Å–æ–±—ã—Ç–∏—è –¥–ª—è to_name

                # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–º—è —Å–æ–±—ã—Ç–∏—è –¥–ª—è —Ç–æ—á–∫–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
                # –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–æ, —Ç.–∫. —Å–µ–≥–º–µ–Ω—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ —Å—Ç—Ä–æ–≥–æ –ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å–æ–±—ã—Ç–∏–µ –≤ –æ–±—â–µ–º —Å–ª—É—á–∞–µ
                # –Ω–æ –¥–ª—è –Ω–∞—à–µ–π –ª–æ–≥–∏–∫–∏ (–æ—Ç —é–∑–µ—Ä–∞ –∫ –∫–∞–∂–¥–æ–º—É —Å–æ–±—ã—Ç–∏—é –ò–õ–ò –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ) –¥–æ–ª–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å
                target_event_for_segment: Optional[Event] = None
                if multiple_days and idx < len(current_events):
                    target_event_for_segment = current_events[idx]
                    to_name = f"¬´{target_event_for_segment.name}¬ª"
                elif not multiple_days and idx < len(
                    current_events
                ):  # –ï—Å–ª–∏ user_start_address, —Ç–æ idx = 0 —ç—Ç–æ –ø–µ—Ä–≤–æ–µ —Å–æ–±—ã—Ç–∏–µ
                    if collected_data.get("user_start_address_original") and idx < len(
                        current_events
                    ):
                        target_event_for_segment = current_events[idx]
                        to_name = f"¬´{target_event_for_segment.name}¬ª"
                    elif not collected_data.get(
                        "user_start_address_original"
                    ) and idx + 1 < len(
                        current_events
                    ):  # –ú–∞—Ä—à—Ä—É—Ç –º–µ–∂–¥—É —Å–æ–±—ã—Ç–∏—è–º–∏
                        target_event_for_segment = current_events[idx + 1]
                        to_name = f"¬´{target_event_for_segment.name}¬ª"

                segment_text = f"  {idx+1}. –û—Ç '{from_name}' –¥–æ '{to_name}': "
                if segment.segment_status == "success":
                    segment_text += f"{segment.duration_text or '? –º–∏–Ω'}, {segment.distance_text or '? –∫–º'}."
                else:
                    segment_text += f"–Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å ({segment.segment_error_message or '–ø—Ä–∏—á–∏–Ω–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞'})."
                response_parts.append(segment_text)

            if current_route_details_obj.status == "partial_success":
                response_parts.append("\n  –ù–µ –≤—Å–µ —á–∞—Å—Ç–∏ –º–∞—Ä—à—Ä—É—Ç–∞ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å.")
            elif (
                not multiple_days
                and current_route_details_obj.total_duration_text
                and len(current_route_details_obj.segments) > 1
            ):  # –û–±—â–µ–µ –¥–ª—è –æ–¥–Ω–æ–¥–Ω–µ–≤–Ω–æ–≥–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ
                response_parts.append(
                    f"\n  –û–±—â–µ–µ –≤—Ä–µ–º—è –≤ –ø—É—Ç–∏ –ø–æ –º–∞—Ä—à—Ä—É—Ç—É: {current_route_details_obj.total_duration_text}."
                )

        elif current_route_details_obj.status != "success":
            response_parts.append(
                f"\n–ú–∞—Ä—à—Ä—É—Ç: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å ({current_route_details_obj.error_message or '–ø—Ä–∏—á–∏–Ω–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞'})."
            )

    response_parts.append(
        "\n\n–ü–ª–∞–Ω –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π. –ï—Å–ª–∏ –∑–∞—Ö–æ—Ç–∏—Ç–µ —á—Ç–æ-—Ç–æ –µ—â–µ, –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å!"
    )
    full_plan_text = "\n".join(response_parts)
    new_messages = state.get("messages", []) + [AIMessage(content=full_plan_text)]  # type: ignore

    # –û—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    # (–∫—Ä–æ–º–µ messages, –∫–æ—Ç–æ—Ä—ã–µ LangGraph –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç)
    # –≠—Ç–æ –ª—É—á—à–µ –¥–µ–ª–∞—Ç—å –≤ —É—Å–ª–æ–≤–Ω–æ–º —Ä–µ–±—Ä–µ, –≤–µ–¥—É—â–µ–º –∫ __END__, –∏–ª–∏ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ /start
    final_collected_data = {}  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–æ–≤–æ–≥–æ —Ü–∏–∫–ª–∞

    return {
        "messages": new_messages,
        "status_message_to_user": full_plan_text,
        "collected_data": final_collected_data,  # –û—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        "current_events": [],
        "current_route_details": None,
        "is_initial_plan_proposed": False,
        "is_full_plan_with_route_proposed": False,  # –ü–ª–∞–Ω —É–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –∫–∞–∫ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π
        "awaiting_final_confirmation": False,
        "awaiting_fallback_confirmation": False,
        "pending_fallback_event": None,
    }


# --- –£–∑–µ–ª 7: –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –ø–æ –ø–ª–∞–Ω—É ---
async def handle_plan_feedback_node(state: AgentState) -> Dict[str, Any]:
    logger.info("Node: handle_plan_feedback_node executing...")
    messages = state.get("messages", [])
    collected_data: CollectedUserData = dict(state.get("collected_data", {}))  # type: ignore
    current_events: Optional[List[Event]] = state.get("current_events")

    if not messages or not isinstance(messages[-1], HumanMessage):
        logger.warning("handle_plan_feedback_node: No human feedback message found.")
        return {
            "status_message_to_user": "–ù–µ –ø–æ–ª—É—á–∏–ª –≤–∞—à–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ –ø–æ –ø–ª–∞–Ω—É.",
            "awaiting_final_confirmation": True,
            "collected_data": collected_data,
            "messages": messages,
        }

    user_feedback = messages[-1].content
    llm = get_gigachat_client()
    structured_llm_feedback = llm.with_structured_output(AnalyzedFeedback)
    plan_summary_parts = []
    if current_events:
        for i, event in enumerate(current_events):
            plan_summary_parts.append(
                f"–ú–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ {i+1}: {event.name} ({event.start_time_naive_event_tz.strftime('%d.%m %H:%M')})"
            )
    current_route_details: Optional[RouteDetails] = state.get("current_route_details")  # type: ignore
    if current_route_details and current_route_details.total_duration_text:
        plan_summary_parts.append(
            f"–ú–∞—Ä—à—Ä—É—Ç: ~{current_route_details.total_duration_text}"
        )
    current_plan_summary_str = (
        "\n".join(plan_summary_parts)
        if plan_summary_parts
        else "–ü–ª–∞–Ω –ø–æ–∫–∞ –Ω–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω."
    )
    prompt_for_feedback_analysis = PLAN_FEEDBACK_ANALYSIS_PROMPT.format(
        current_plan_summary=current_plan_summary_str, user_feedback=user_feedback
    )

    try:
        analyzed_result: AnalyzedFeedback = await structured_llm_feedback.ainvoke(
            prompt_for_feedback_analysis
        )
        logger.info(
            f"LLM Analyzed Feedback: {analyzed_result.model_dump_json(indent=2)}"
        )
        intent = analyzed_result.intent_type
        changes = analyzed_result.change_details
        next_state_update: Dict[str, Any] = {
            "awaiting_final_confirmation": False,
            "collected_data": collected_data,
            "current_events": list(current_events) if current_events else [],
        }

        if intent == "confirm_plan":
            logger.info("User confirmed the plan.")
            next_state_update["status_message_to_user"] = (
                "–û—Ç–ª–∏—á–Ω–æ! –†–∞–¥ –±—ã–ª –ø–æ–º–æ—á—å. –ï—Å–ª–∏ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è —á—Ç–æ-—Ç–æ –µ—â–µ, –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å!"
            )
            next_state_update["is_initial_plan_proposed"] = False
            next_state_update["is_full_plan_with_route_proposed"] = False
        elif intent == "request_change" and changes:
            logger.info(f"User requested changes: {changes}")
            next_state_update["previous_confirmed_collected_data"] = dict(
                collected_data
            )
            next_state_update["previous_confirmed_events"] = (
                list(current_events) if current_events else []
            )
            next_state_update["is_initial_plan_proposed"] = False
            next_state_update["is_full_plan_with_route_proposed"] = False
            next_state_update["current_events"] = []
            next_state_update["current_route_details"] = None

            new_collected_data = dict(next_state_update["collected_data"])  # type: ignore
            new_collected_data["clarification_needed_fields"] = []
            change_target = changes.get("change_target")
            new_value = changes.get("new_value")

            if change_target == "budget":
                if isinstance(new_value, (int, float)):
                    new_collected_data["budget_current_search"] = int(new_value)
                    new_collected_data["budget_original"] = int(new_value)
                else:
                    new_collected_data.setdefault(
                        "clarification_needed_fields", []
                    ).append("budget_original")
                    next_state_update["clarification_context"] = (
                        f"–£–∫–∞–∂–∏—Ç–µ –±—é–¥–∂–µ—Ç —á–∏—Å–ª–æ–º. –í—ã: '{new_value}'."
                    )
            elif change_target in ["date", "time"]:
                if isinstance(new_value, str):
                    parsed_date_res = await datetime_parser_tool.ainvoke(
                        {
                            "natural_language_date": new_value,
                            "base_date_iso": datetime.now().isoformat(),
                        }
                    )
                    if parsed_date_res.get("datetime_iso"):
                        new_collected_data["parsed_dates_iso"] = [
                            parsed_date_res["datetime_iso"]
                        ]
                        new_collected_data["dates_description_original"] = new_value
                        if parsed_date_res.get("end_datetime_iso"):
                            new_collected_data["parsed_end_dates_iso"] = [
                                parsed_date_res["end_datetime_iso"]
                            ]
                        elif "parsed_end_dates_iso" in new_collected_data:
                            del new_collected_data["parsed_end_dates_iso"]
                        if parsed_date_res.get("is_ambiguous"):
                            new_collected_data.setdefault(
                                "clarification_needed_fields", []
                            ).append("dates_description_original")
                            next_state_update["clarification_context"] = (
                                parsed_date_res.get("clarification_needed")
                            )
                    else:
                        new_collected_data.setdefault(
                            "clarification_needed_fields", []
                        ).append("dates_description_original")
                        next_state_update["clarification_context"] = (
                            f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å '{new_value}'. –£—Ç–æ—á–Ω–∏—Ç–µ."
                        )
                else:
                    new_collected_data.setdefault(
                        "clarification_needed_fields", []
                    ).append("dates_description_original")
                    next_state_update["clarification_context"] = (
                        f"–û–ø–∏—à–∏—Ç–µ –¥–∞—Ç—É/–≤—Ä–µ–º—è —Ç–µ–∫—Å—Ç–æ–º. –í—ã: '{new_value}'."
                    )
            elif change_target in ["interests", "type"] or "event_" in str(
                change_target
            ):
                # ... (–ª–æ–≥–∏–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –∫–∞–∫ –≤ –ø—Ä–æ—à–ª–æ–º –æ—Ç–≤–µ—Ç–µ)
                new_interests_str_list = (
                    [new_value]
                    if isinstance(new_value, str)
                    else (
                        new_value
                        if isinstance(new_value, list)
                        and all(isinstance(s, str) for s in new_value)
                        else []
                    )
                )
                if new_interests_str_list:
                    new_collected_data["interests_original"] = new_interests_str_list
                    mapped_keys = []
                    for s_int in new_interests_str_list:
                        s_l = s_int.lower()
                        key_afisha = None
                        if "—Ñ–∏–ª—å–º" in s_l or "–∫–∏–Ω–æ" in s_l:
                            key_afisha = "Movie"
                        # ... –¥—Ä—É–≥–∏–µ –º–∞–ø–ø–∏–Ω–≥–∏ ...
                        elif "—Ç–µ–∞—Ç—Ä" in s_l:
                            key_afisha = "Performance"
                        if not key_afisha:
                            key_afisha = s_int.capitalize()
                        mapped_keys.append(key_afisha)
                    new_collected_data["interests_keys_afisha"] = list(set(mapped_keys))
                else:
                    new_collected_data.setdefault(
                        "clarification_needed_fields", []
                    ).append("interests_original")
                    next_state_update["clarification_context"] = (
                        f"–ù–∞–∑–æ–≤–∏—Ç–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã. –í—ã: '{new_value}'."
                    )
            elif change_target == "start_location":
                if isinstance(new_value, str):
                    new_collected_data["user_start_address_original"] = new_value
                    new_collected_data["user_start_address_validated_coords"] = None
                else:
                    new_collected_data.setdefault(
                        "clarification_needed_fields", []
                    ).append("user_start_address_original")
                    next_state_update["clarification_context"] = (
                        f"–£–∫–∞–∂–∏—Ç–µ –∞–¥—Ä–µ—Å. –í—ã: '{new_value}'."
                    )
            else:
                logger.warning(f"Unknown change_target: {change_target}")
                next_state_update["clarification_context"] = "–ù–µ –ø–æ–Ω—è–ª, —á—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—å."
            next_state_update["collected_data"] = new_collected_data
            next_state_update["pending_plan_modification_request"] = None
        elif intent == "new_search":
            next_state_update["status_message_to_user"] = (
                "–•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π—Ç–µ –Ω–∞—á–Ω–µ–º –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫. –ß—Ç–æ –±—ã –≤—ã —Ö–æ—Ç–µ–ª–∏ –Ω–∞–π—Ç–∏?"
            )
            next_state_update["collected_data"] = {}
            next_state_update["current_events"] = []
            next_state_update["current_route_details"] = None
            next_state_update["is_initial_plan_proposed"] = False
            next_state_update["is_full_plan_with_route_proposed"] = False
        else:  # clarify_misunderstanding –∏–ª–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ
            next_state_update["status_message_to_user"] = (
                "–Ø –≤–∞—Å –Ω–µ —Å–æ–≤—Å–µ–º –ø–æ–Ω—è–ª. –ü–æ–ø—Ä–æ–±—É–µ—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –Ω–æ–≤—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏?"
            )
            next_state_update["awaiting_final_confirmation"] = (
                True  # –û—Å—Ç–∞–µ–º—Å—è –Ω–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–∏ —Ç–µ–∫—É—â–µ–≥–æ –ø–ª–∞–Ω–∞
            )

        if next_state_update.get("status_message_to_user"):
            next_state_update["messages"] = messages + [
                AIMessage(content=next_state_update["status_message_to_user"])
            ]
        else:
            next_state_update["messages"] = messages
        return next_state_update
    except Exception as e:
        logger.error(f"Error analyzing feedback: {e}", exc_info=True)
        msg = "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—Ç–≤–µ—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
        return {
            "status_message_to_user": msg,
            "awaiting_final_confirmation": True,
            "messages": messages + [AIMessage(content=msg)],
            "collected_data": collected_data,
        }


# --- –£–∑–µ–ª 8: –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π (–¥–ª—è –ü—Ä–∏–º–µ—Ä–∞ 2 –∏–∑ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏) ---
async def confirm_changes_node(
    state: AgentState,
) -> Dict[str, Any]:  # –í–µ—Ä–æ—è—Ç–Ω–æ, –Ω–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∞–∫—Ç–∏–≤–Ω–æ
    logger.info("Node: confirm_changes_node executing (likely deprecated)...")
    messages = state.get("messages", [])
    pending_modification = state.get("pending_plan_modification_request", {})
    if not pending_modification:
        return {
            "status_message_to_user": "–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫.",
            "messages": messages,
            "collected_data": state.get("collected_data"),
        }
    change_summary = "; ".join([f"{k}: {v}" for k, v in pending_modification.items()])
    confirmation_question = (
        f"–ü—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–Ω–∏–º–∞—é, –≤—ã —Ö–æ—Ç–∏—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å: {change_summary}? (–¥–∞/–Ω–µ—Ç)"
    )
    new_messages = messages + [AIMessage(content=confirmation_question)]
    return {
        "messages": new_messages,
        "status_message_to_user": confirmation_question,
        "collected_data": state.get("collected_data"),
    }


# --- –£–∑–µ–ª 9: –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ, –µ—Å–ª–∏ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã ---
async def error_node(state: AgentState) -> Dict[str, Any]:
    logger.info("Node: error_node executing...")
    collected_data: CollectedUserData = dict(state.get("collected_data", {}))  # type: ignore
    not_found_keys: List[str] = collected_data.get("not_found_interest_keys", [])  # type: ignore
    original_interests: List[str] = collected_data.get("interests_original", [])  # type: ignore
    search_criteria_parts = []
    if collected_data.get("city_name"):
        search_criteria_parts.append(f"–≥–æ—Ä–æ–¥ '{collected_data['city_name']}'")
    if collected_data.get("dates_description_original"):
        search_criteria_parts.append(
            f"–¥–∞—Ç—ã '{collected_data['dates_description_original']}'"
        )

    key_to_name = {
        "Movie": "—Ñ–∏–ª—å–º—ã",
        "Performance": "—Å–ø–µ–∫—Ç–∞–∫–ª–∏",
        "Concert": "–∫–æ–Ω—Ü–µ—Ä—Ç—ã",
        "Exhibition": "–≤—ã—Å—Ç–∞–≤–∫–∏",
        "SportEvent": "—Å–ø–æ—Ä—Ç",
        "Excursion": "—ç–∫—Å–∫—É—Ä—Å–∏–∏",
        "Event": "—Å–æ–±—ã—Ç–∏—è",
    }
    if not_found_keys:
        names = [key_to_name.get(k, k) for k in not_found_keys]
        if len(not_found_keys) == len(collected_data.get("interests_keys_afisha", [])):
            search_criteria_parts.append(f"–∏–Ω—Ç–µ—Ä–µ—Å—ã '{', '.join(original_interests)}'")
        else:
            search_criteria_parts.append(
                f"–∏–Ω—Ç–µ—Ä–µ—Å—ã '{', '.join(original_interests)}' (–Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {', '.join(names)})"
            )
    elif original_interests:
        search_criteria_parts.append(f"–∏–Ω—Ç–µ—Ä–µ—Å—ã '{', '.join(original_interests)}'")

    search_criteria_summary = (
        ", ".join(search_criteria_parts)
        if search_criteria_parts
        else "—É–∫–∞–∑–∞–Ω–Ω—ã–º –≤–∞–º–∏ –∫—Ä–∏—Ç–µ—Ä–∏—è–º"
    )
    error_msg = EVENT_NOT_FOUND_PROMPT_TEMPLATE.format(
        search_criteria_summary=search_criteria_summary
    )

    if "not_found_interest_keys" in collected_data:
        del collected_data["not_found_interest_keys"]  # type: ignore
    if "fallback_candidates" in collected_data:
        del collected_data["fallback_candidates"]  # type: ignore

    new_messages = state.get("messages", []) + [AIMessage(content=error_msg)]  # type: ignore
    return {
        "messages": new_messages,
        "status_message_to_user": error_msg,
        "current_events": [],
        "current_route_details": None,
        "is_initial_plan_proposed": False,
        "is_full_plan_with_route_proposed": False,
        "awaiting_final_confirmation": False,
        "collected_data": collected_data,
    }
